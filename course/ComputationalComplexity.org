#+TITLE: Computational Complexity
#+AUTHOR: Ryan O'Donnell

#+EXPORT_FILE_NAME: ../latex/ComputationalComplexity/ComputationalComplexity.tex
#+LATEX_HEADER: \input{preamble.tex}
* Definition of macros                                               :ignore:
#+LATEX_HEADER: \def \TIME {\text{TIME}}
#+LATEX_HEADER: \def \EXP {\textbf{EXP}}
#+LATEX_HEADER: \def \SPACE {\textbf{SPACE}}
#+LATEX_HEADER: \def \PSPACE {\textbf{PSPACE}}
#+LATEX_HEADER: \def \NTIME {\textbf{NTIME}}
#+LATEX_HEADER: \def \NP {\textbf{NP}}
#+LATEX_HEADER: \def \coNP {\textbf{coNP}}
#+LATEX_HEADER: \def \NEXP {\textbf{NEXP}}
#+LATEX_HEADER: \def \NE {\textbf{NE}}
#+LATEX_HEADER: \def \Pspoly {\textbf{P}/poly}
#+LATEX_HEADER: \def \SAT {\text{SAT}}
#+LATEX_HEADER: \def \AC {\text{AC}}
#+LATEX_HEADER: \def \BPP {\textbf{BPP}}
#+LATEX_HEADER: \def \start {\text{start}}
#+LATEX_HEADER: \def \tend {\text{end}}
#+LATEX_HEADER: \def \halt {\text{halt}}
#+LATEX_HEADER: \def \pad {\text{pad}}
#+LATEX_HEADER: \def \HALT {\text{HALT}}
#+LATEX_HEADER: \def \DTIME {\textbf{DTIME}}
#+LATEX_HEADER: \def \NP {\textbf{NP}}
#+LATEX_HEADER: \def \INDSET {\texttt{INDSET}}
#+LATEX_HEADER: \def \accept {\text{accept}}
#+LATEX_HEADER: \def \TMSAT {\texttt{TMSAT}}
#+LATEX_HEADER: \def \SAT {\texttt{SAT}}
#+LATEX_HEADER: \def \ZOIPROG {\texttt{1/0 IPROG}}
#+LATEX_HEADER: \def \dHAMPATH {\texttt{dHAMPATH}}
#+LATEX_HEADER: \def \TAUTOLOGY {\texttt{TAUTOLOGY}}
* Notational conventions
  Use \(\lcorner{x}\) to denote some canonical binary representation of the object \(x\).

  The length of a string \(x\) is denoted by \(\abs{x}\)
* Lecture 1  
** Lecture notes
  \(\TIME(t(n))=\)all languages \(L\) decidable in \(O(t(n))\) steps on input of length \(n\)

  Language \(L\)(\(\Sigma^*\)) \(\equiv\) decision problem -> yes/no problem

  | Language \(L\)                    | decision problem | \(f:\{0,1\}^*\to\{0,1\}\)        |
  | \(\Sigma^*\)                           | yes/no problem   | \(x\in L\Leftrightarrow f(x)=1\) |
  | decide if a string is in language |                  |                                  |

  Model: multitape Turing machine (TM)

  Time Hierarchy Theorem (More time = more power to decide a language)

  \(\Rightarrow\) \(\TIME(n^2)\subsetneq\TIME(n^3)\)

  \(\bP=\TIME(poly(n))\), \(\EXP=\TIME(2^{poly(n)})\),\(\bE=\TIME(2^{O(n)})\)

  \(\Rightarrow\bP\subsetneq\bE\subsetneq\EXP\)

  \(\SPACE(s(n))=\) langs decidable using tape cells \(\subseteq O(s(n))\)

  \(\TIME(f(n))\subseteq\SPACE(f(n))\)

  (each operation takes a cell)

  \(\PSPACE=\SPACE(poly(n))\)
  
  \(\bP\subseteq\PSPACE\)

  \(\SPACE(f(n))\subseteq\TIME(2^{O(f(n))})\) (since only \(O(f(n))\) possible states if each state
  is different)

    \(\bL=\SPACE(\log n)\)

    \(\bL\subseteq\bP\subseteq\PSPACE\subseteq\EXP\)

    #+ATTR_LATEX: :options [HPV77]
    #+BEGIN_theorem
    \(\TIME(t(n))\subseteq\SPACE(\frac{t(n)}{\log t(n)})\subsetneq\SPACE(t(n))\)
    #+END_theorem

    Space is more valuable than time.

    \(\NP=\NTIME(poly(n))\) computed by nondeterministic multitape turing machine

    \(\NE=\NTIME(2^{O(n)})\)

    Circuits - "Non-uniform" model

    "Non-uniform" different algorithms for different input length

    \(\bP/poly\)=langs decidable by \(poly(n)\)-size circuit familys

    \(\bP\subsetneq\bP/poly\)

    if \(\NP\neq\bP\) then \(\NP\not\subseteq\Pspoly\)

    which is equivalent to \(\SAT\) not decidable by \(poly(n)\)-size circuits

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    there exists language with no poly-size constant-depth circuits (actually in \(\bP\))
    #+END_theorem

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    CLIQUE requires exponential size AND/OR circuits
    #+END_theorem

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    There exists a language \(L\in\bP\) requiring circuit families of size \(\ge3 n\)
    #+END_theorem


    #+ATTR_LATEX: :options [Santhanam theorem]
    #+BEGIN_theorem
    for all \(c\) there exists \(L\) s.t. \(L\) is not computable by \(O(n^c)\)-size circuit
    #+END_theorem

    #+ATTR_LATEX: :options [William's Theorem]
    #+BEGIN_theorem
    \(\exists L\in\NEXP\) is not computable by \(\AC^0[6]\) (constant depth, \(poly(n)\) size, also
    get \(\mod6\) gates)
    #+END_theorem

    Randomness

    \(\BPP=\) langs decidable in \(poly(n)\)-time using randomness

    \(\bP\subseteq\BPP\subseteq\EXP\)

    PIT = "polynomial identity testing" that are in \(\BPP\), but we don't know if they are in \(\bP\)

    Hardness vs Randomness Paradigm
    
** Book

*** Chapter 1: The computational model
    
**** Efficiency and Running Time
    #+ATTR_LATEX: :options []
    #+BEGIN_definition
    A TM \(M\) is described by a tuple \((\Gamma,Q,\delta)\) containing
    * A finite set \Gamma of the symbols that \(M\)'s tapes can contain. We assume that \Gamma contains a
      designated "blank" symbol, denoted \(\Box\); a designated "start" symbol, denoted \(\rhd\);
      and the numbers 0 and 1. We call \Gamma the *alphabet* of \(M\)
    * A finite set \(Q\) of possible states \(M\)' register can be in. We assume that \(Q\) contains
      a designated start state, denoted \(q_{\start}\), and a designated halting state, denoted \(q_{\halt}\)
    * A function \(\delta:Q\times\Gamma^k\to Q\times\Gamma^{k-1}\times\{\text{L,S,R}\}^k\),
      where \(k\ge2\), describing the rules \(M\) use in performing each step. This function is
      called the *transition function* of \(M\)
    #+END_definition

    #+ATTR_LATEX: :width 0.8\textwidth
    [[/media/wu/file/stuuudy/notes/images/ComputationalComplexity/1.png]]

    
    #+ATTR_LATEX: :options [Computing a function and running time]
    #+BEGIN_definition
    Let \(f:\{0,1\}^*\to\{0,1\}\) and let \(T:\N\to\N\) be some functions, and let \(M\) be a Turing
    machine. We say that \(M\) *computes* \(f\) if for every \(x\in\{0,1\}^*\), whenever \(M\) is
    initialized to the start configuration on input \(x\), then it halts with \(f(x)\) written on
    its output tape. We say \(M\) *computes \(f\) in \(T(n)\)-time* if its computation on every
    input \(x\) requires at most \(T(\abs{x})\) steps
    #+END_definition

    A function \(T:\N\to\N\) is *time constructible* if \(T(n)\ge n\) and there is a TM \(M\) that
    computes the function \(x\mapsto\lcorner{T(\abs{x})}\) in time \(T(n)\). (\(\lcorner{T(\abs{x})}\)
    denotes the binary representation of the number \(T(\abs{x})\)). The restriction \(T(n)\ge n\) is
    to allow the algorithm time to read its input.

    #+ATTR_LATEX: :options []
    #+BEGIN_proposition
    For every \(f:\{0,1\}^*\to\{0,1\}\) and a time-constructible b\(T:\N\to\N\), if \(f\) is
    computable in time \(T(n)\) by a TM \(M\) using alphabet \Gamma, then it's computable in time
    \(4\log\abs{\Gamma}T(n)\) by a TM \(M\) using the alphabet \(\{0,1,\Box,\rhd\}\).
    #+END_proposition

    #+BEGIN_proof
    Let \(M\) be a TM with alphabet \Gamma, \(k\) tapes and state set \(Q\) that computes the
    function \(f\) in \(T(n)\) times. We describe an equivalent TM \(\tilde{M}\) computing \(f\)
    with alphabet \(\{0,1,\Box,\rhd\}\), \(k\) tapes and a set \(Q'\) of states.

    One can encode any member of \Gamma using \(\log\abs{\Gamma}\) bits. Thus each of \(\tilde{M}\)'s work
    tapes will simply encode one of \(M\)'s tapes: For every cell in \(M\)'s tape we will
    have \(\log\abs{\Gamma}\) cells in the corresponding tape of \(\tilde{M}\)

    To simulate one step of \(M\), the machine \(\tilde{M}\) will 1. use \(\log\abs{\Gamma}\) steps to
    read from each tape the \(\log\abs{\Gamma}\) bits encoding of a symbol of \Gamma 2. use its state register
    to store the symbols read 3. use \(M\)'s transition function to compute the symbols \(M\) writes
    and \(M\)'s new state given this information 4. store this information in its state register 5.
    use \(\log\abs{\Gamma}\) steps to write the encodings of these symbols on its tapes

    
    #+END_proof

    #+ATTR_LATEX: :options []
    #+BEGIN_proposition
    label:prop1.6
    Define a single-tape Turing machine to be a TM that has only one read-write tape. For every
    \(f:\{0,1\}^*\to\{0,1\}\) and time-constructible \(T:\N\to\N\) if \(f\) is computable in
    time \(T(n)\) by a TM \(M\) using \(k\) tapes, then it is computable in time \(5kT(n)^2\) by a
    single-tape TM \(M\)
    #+END_proposition

    #+BEGIN_proof
    The TM \(\tilde{M}\) encodes \(k\) tapes of \(M\) on a single tape by using
    locations \(1,k+1,2k+1,\dots\) to encode the first tape, locations \(2,k+2,2k+2,\dots\) to
    encode the second tape etc. For every symbol \(a\) in \(M\)'s alphabet, \(\tilde{M}\) will
    contain both the symbol \(a\) and the symbol \(\hat{a}\). In the encoding of each tape, exactly
    one symbol will be of the "^ type", indicating that the corresponding head of \(M\) is
    positioned in that location. \(\tilde{M}\) will not touch the first \(n+1\) locations of its
    tape (where the input is located) but rather start by taking \(O(n^2)\) steps to copy the input
    bit by bit into the rest of the tape, while encoding it in the above way.
    #+END_proof

    #+ATTR_LATEX: :options [Oblivious Turing machines]
    #+BEGIN_remark
    One can ensure that the proof of Proposition ref:prop1.6 yields a TM \(\tilde{M}\) with the
    following property: its head movements do not depend on the input but only depend on the input
    length. That is, every input \(x\in\{0,1\}^*\) and \(i\in\N\), the location of each of \(M\)'s
    at the \(i\)th step of execution on input \(x\) is only a function of \(\abs{x}\) and \(i\). A
    machine with this property is called *oblivious*.
    #+END_remark

    #+ATTR_LATEX: :options []
    #+BEGIN_proposition
    Define a bidirectional TM to be a TM whose tapes are infinite in both directions. For
    every \(f:\{0,1\}^*\to\{0,1\}^*\) and time-constructible \(T:\N\to\N\) if \(f\) is computable in
    time \(T(n)\) by a directional TM M, then it is computable in time \(4T(n)\) by a standard
    (undirectional) TM \(\tilde{M}\)
    #+END_proposition

    #+BEGIN_proof
    #+ATTR_LATEX: :width .5\textwidth
    [[/media/wu/file/stuuudy/notes/images/ComputationalComplexity/2.png]]

    If \(M\) uses alphabet \Gamma, then \(\tilde{M}\) will use the alphabet \(\Gamma^2\) 
    #+END_proof

**** Machines as Strings and the Universal Turing Machine
     We will also find it convenient to assume that our representation scheme satisfies the following
     properties:
     1. We will also findit convenient to assume that our representation scheme satisfies the
        following properties:
     2. Every TM is representedby infinitely many strings
     
     We denote by \(\lcorner{M}\) the TM \(M\)'s representation as a binary string. If \alpha is a string
     then \(M_\alpha\) denotes the TM that \alpha represents.

     #+ATTR_LATEX: :options [Efficient universal Turing machine]
     #+BEGIN_theorem
     label:thm1.9
     There exists a TM \(\calu\) s.t. for
     every \(x,\alpha\in\{0,1\}^*\), \(\calu(x,\alpha)=M_\alpha(x)\). Moreover, if \(M_{\alpha}\) halts on
     input \(x\) within \(T\) steps then \(\calu(x,\alpha)\) falts within \(CT\log T\) steps, where \(C\)
     is a number independent of \(\abs{x}\) and depending only on \(M_\alpha\)'s alphabet size,
     number of tapes and number of states.
     #+END_theorem

     #+ATTR_LATEX: :options [Proof of relaxed version of theorem \cite{thm1.9}]
     #+BEGIN_proof
     We assume \(M\) has a single work tape (in addition to the input and output tape) and uses he
     alphabet \(\{\rhd,\Box,0,1\}\). The reason is that \(\calu\) can transform a representation of
     every TM \(M\) into a representation of an equivalent TM \(\tilde{M}\) that satisfies these
     properties. (which my takes \(C'T^2\) time)

     #+ATTR_LATEX: :float H :width .5\textwidth
     [[/media/wu/file/stuuudy/notes/images/ComputationalComplexity/3.png]]
     #+END_proof


**** Uncomputablity: An Introduction
     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     There exists a function \(\text{UC}:\{0,1\}^*\to\{0,1\}\) that is not computable by any TM
     #+END_theorem

     #+BEGIN_proof
     For every \(\alpha\in\{0,1\}^*\), if \(M_{\alpha}(\alpha)=1\) then \(\text{UC}(\alpha)=0\);
     otherwise \(\text{UC}(\alpha)=1\).

     If its computable, then there exists a TM \(M\) s.t. \(M(\alpha)=\text{UC}(\alpha)\), then
     \(M(\lcorner{M})=\text{UC}(\lcorner{M})\)
     #+END_proof

     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     \(\HALT\) is not computable by any TM
     #+END_theorem

**** The Class \(\bP\)
     A *complexity class* is a set of function that can be computed within given resource bounds.

     [[index:decide]]
     We say that a machine *decides* a language \(L\subseteq\{0,1\}^*\) if it computes the
     function \(f_L:\{0,1\}^*\to\{0,1\}\) where \(f_L(x)=1\Leftrightarrow x\in L\)

     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     Let \(T:\N\to\N\) be some function. A language \(L\) is in \(\DTIME(T(n))\) iff there is a
     Turing machine that runs in \(c\dot T(n)\) for some constant \(c>0\) and decides \(L\).
     #+END_definition

     The D in \(\DTIME\) refers to "deterministic".

     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     \(\bP=\bigcup_{c\ge1}\DTIME(n^c)\)
     #+END_definition

*** NP and NP completeness

**** The Class \(\NP\)
     [[index:$\NP$]]
     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     A language \(L\subseteq\{0,1\}^*\) is in \(\NP\) if there exists  a polynomial \(p:\N\to\N\)
     and a polynomial-time TM \(M\) (called the *verifier* for \(L\)) s.t. for
     every \(x\in\{0,1\}^*\)
     \begin{equation*}
x\in L\Leftrightarrow \exists u\in\{0,1\}^{p(\abs{x})}\text{ s.t. }M(x,u)=1
     \end{equation*}
     If \(x\in L\) and \(u\in\{0,1\}^{p(\abs{x})}\) satisfy \(M(x,u)=1\) then we call \(u\) a
     *certificate* for \(x\)
     #+END_definition

     #+ATTR_LATEX: :options [\(\INDSET\in\NP\)]
     #+BEGIN_examplle
     By representing the possible invitees to a dinner party with the vertices of a graph having an
     edge between any two people who don't get along. The dinner party computational problem becomes
     the problem of finding a maximum sized *independent set* (set of vertices without any common
     edges) in a given graph. The corresponding language is
     \begin{equation*}
\INDSET=\{\la G,k\ra:\exists S\subseteq V(G)\text{ s.t. }\abs{S}\ge k\text{ and }\forall u,v\in S, \ove{uv}\not\in E(G)\}
     \end{equation*}

     Consider the following polynomial-time algorithm \(M\): Given a pair \(\la G,k\ra\) and a
     string \(u\in\{0,1\}^*\), output 1 iff \(u\) encodes a list of \(k\) vertices of \(G\) s.t.
     there is no edge between any two members of the list. Note that if \(n\) is the number of
     vertices in \(G\), then a list of \(k\) vertices can be encoded using \(O(k\log n)\) bits,
     where \(n\) is the number of vertices in \(G\). Thus \(u\) is a string of at
     most \(O(n\log n)\) bits, which is polynomial in the size of the representation of \(G\).
     #+END_examplle

     #+ATTR_LATEX: :options []
     #+BEGIN_proposition
     Let \(\EXP=\bigcup_{c>1}\DTIME(2^{n^c})\). Then \(\bP\subseteq\NP\subseteq\EXP\)
     #+END_proposition

     #+BEGIN_proof
     \(\bP\subseteq\NP\). Suppose \(L\in\bP\) is decided in polynomial-time by a TM \(N\).
     Then we take \(N\) as the machine \(M\) and make \(p(x)\) the zero polynomial

     \(\NP\subseteq\EXP\). We can decide \(L\) in time \(2^{O(p(n))}\)  by enumerating all
     possible \(n\) and using \(M\) to check whether \(u\) is a valid certificate for the
     input \(x\). Note that \(p(n)=O(n^c)\) for some \(c>1\), the number of choices for \(u\) is \(2^{O(n^c)}\).
     #+END_proof

     \(\NP\) stands for *nondeterministic polynomial time*.

     NDTM has *two* transition function \(\delta_0\) and \(\delta_1\), and a special state denoted
     by \(q_{\accept}\). When an NDTM \(M\) computes a function, we envision that at each
     computational step \(M\) makes an arbitrary choice at to which of its two transition functions
     to apply. For every input \(x\), we say that \(M(x)=1\) if there *exists* some sequence of this
     choices that would make \(M\) reach \(q_{\accept}\) on input \(x\). We say that \(M\) runs
     in \(T(n)\) time if for every input \(x\in\{0,1\}^*\) and every sequence of nondeterministic
     choices, \(M\) reaches the halting state or \(q_{\accept}\) within \(T(\abs{x})\) steps

     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     For every function \(f:\N\to\N\) and \(L\subseteq\{0,1\}^*\) we say that \(L\in\NTIME(T(n))\)
     if there is a constant \(c>0\) and a \(c\dot T(n)\)-time NDTM \(M\) s.t. for
     every \(x\in\{0,1\}^*\), \(x\in L\Leftrightarrow M(x)=1\)
     #+END_definition

     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     \(\NP=\bigcup_{c\in\N}\NTIME(n^c)\)
     #+END_theorem

     #+BEGIN_proof
     The main idea is that the sequence of nondeterministic choices made by an accepting computation
     of an NDTM can be viewedas a certificate that the input is in the language, and vice versa

     Suppose \(p:\N\to\N\) is a polynomial and \(L\) is decidable by a NDTM \(N\) that runs in
     time \(p(n)\). For every \(x\in L\), there is a sequence of nondeterministic choices that
     makes \(N\) reach \(q_{\accept}\) on input \(x\). We can use this sequence as a certificate
     for \(x\). This certificate has length \(p(\abs{x})\) and can be verified in polynomial time by
     a deterministic machine.

     Conversely, if \(L\in\NP\), then we describe a polynomial time NDTM \(N\) that decides \(L\).
     On input \(x\), it uses the ability to make nondeterministic choices to write down a
     string \(u\) of length \(p(\abs{x})\). (Having transition \(\delta_0\) correspond to writing a
     0 and \(\delta_1\) ). Then it runs the deterministic verifier 
     #+END_proof

**** Reducibility and NP-Completeness
     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     A language \(L\subseteq\{0,1\}^*\) is *polynomial-time Karp reducible to a
     language* \(L'\subseteq\{0,1\}^*\), denoted by \(L\le_p L'\) if there is a polynomial-time
     computable function \(f:\{0,1\}^*\to\{0,1\}^*\) s.t. for every \(x\in\{0,1\}^*\),
     \(x\in L\) iff \(f(x)\in L'\)

     We say that \(L'\) is *\(\NP\)-hard* if \(L\le_pL'\) for every \(L\in\NP\). We say that \(L'\)
     is *\(\NP\)-complete* if \(L'\) is \(\NP\)-hard and \(L'\in\NP\)
     #+END_definition

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    1. (Transitivity) If \(L\le_pL'\) and \(L'\le_pL''\) then \(L\le_pL''\)
    2. If language \(L\) is \(\NP\)-hard and \(L\in\bP\) then \(\bP=\NP\)
    3. If language \(L\) is \(\NP\)-complete, then \(L\in\bP\) iff \(\bP=\NP\)
    #+END_theorem

    #+ATTR_LATEX: :options []
    #+BEGIN_theorem
    The following language is \(\NP\)-complete
    \begin{equation*}
\TMSAT=\{\la\alpha,x,1^n,1^t\ra:\exists u\in\{0,1\}^n\text{ s.t. }M_\alpha\text{ outputs }1
\text{ on input }\la x,u\ra\text{ within }t\text{ steps}\}
    \end{equation*}
    #+END_theorem

    #+BEGIN_proof
    There is a polynomial \(p\) and a verifier TM \(M\) s.t. \(x\in L\) iff there is a
    string \(u\in\{0,1\}^{p(\abs{x})}\) satisfying \(M(x,u)=1\) and \(M\) runs in time \(q(n)\) for
    some polynomial \(q\).

    Map every string \(x\in\{0,1\}^*\) to the tuple \(\la\lcorner{M},x,1^{p(\abs{x})},1^{q(m)}\)
    where \(m=\abs{x}+p(\abs{x})\) and \(\lcorner{M}\) denotes the representation of \(M\) as
    string.
    \begin{align*}
&\la\lcorner{M},x,1^{p(\abs{x})},1^{q(m)}\ra\in\TMSAT\\
&\Leftrightarrow\exists u\in\{0,1\}^{p(\abs{x})}\text{ s.t. }M(x,u)\text{ outputs 1 within }q(m)\text{ steps}\\
&\Leftrightarrow x\in L
    \end{align*}
    #+END_proof

**** The Cook-Levin Theorem: Computation is Local
     We denote by \(\SAT\) the language of all satisfiable CNF formulae and by \(3\SAT\) the
     language of all satisfiable 3CNF formulae

     #+ATTR_LATEX: :options [Cook-Levin Theorem]
     #+BEGIN_theorem
     label:thm2.10
     1. \(\SAT\) is \(\NP\)-complete
     2. \(3\SAT\) is \(\NP\)-complete
     #+END_theorem

     #+ATTR_LATEX: :options [Universality of AND, OR, NOT]
     #+BEGIN_lemma
     label:lemma2.13
     For every Boolean function \(f:\{0,1\}^l\to\{0,1\}\), there is an \(l\)-variable CNF formula \varphi
     of size \(l2^l\) s.t. \(\varphi(u)=f(u)\) for every \(u\in\{0,1\}^l\), where the size of a CNF
     formula is defined to be the number of \(\wedge/\vee\) symbols it contains
     #+END_lemma

     #+BEGIN_proof
     For every \(v\in\{0,1\}^l\), there exists a clause \(C_v(z_1,\dots,z_l)\) s.t. \(C_v(v)=0\)
     and \(C_v(u)=1\) for every \(u\neq v\).

     We let \varphi be the AND of all the clauses \(C_v\) for \(v\) s.t. \(f(v)=0\)
     \begin{equation*}
\varphi=\bigwedge_{v:f(v)=0}C_v(z_1,\dots,z_l)
     \end{equation*}
     Note that \varphi has size at most \(l2^l\).
     #+END_proof

     #+ATTR_LATEX: :options []
     #+BEGIN_lemma
     \(\SAT\) is \(\NP\)-hard
     #+END_lemma

     #+BEGIN_proof
     Let \(L\) be an \(\NP\) language. By definition, there is a polynomial time TM \(M\) s.t. for
     every \(x\in\{0,1\}^*\), \(x\in L\Leftrightarrow M(x,u)=1\) for
     some \(u\in\{0,1\}^{p(\abs{x})}\), where \(p:\N\to\N\) is some polynomial. We show \(L\) is
     polynomial-time Karp reducible to \(\SAT\) by describing a polynomial-time
     transformation \(x\to\varphi_x\) from strings to CNF formulae s.t. \(x\in L\) iff \(\varphi_x\)
     is satisfiable. Equivalently
     \begin{equation*}
\varphi_x\in\SAT \quad\text{ iff }\quad\exists u\in\{0,1\}^{p(\abs{x})}
\text{ s.t. }M(x\circ u)=1
     \end{equation*}
     where \(\circ\) denotes concatenation

     Assume \(M\)
     1. \(M\) only has two tapes - an input tape and a work/output tape
     2. \(M\) is an oblivious TM in the sense that its head movement does not depend on the contents
        of its tapes. That is, \(M\)'s computation takes the same time for all inputs of size \(n\),
        and for every \(i\) the location of \(M\)'s head at the \(i\)th step depends only on \(i\)
        and the length of the input


     We can make these assumptions without loss of generality because for every \(T(n)\)-time TM \(M\)
     there exists a two-tape oblivious TM \(\tilde{M}\) computing the same function
     in \(O(T(n)^2)\). Thus in particular, if \(L\in\NP\), then there exists a two-tape oblivious
     polynomial-time TM \(M\) and a polynomial \(p\) s.t.
     \begin{equation}
     \label{eq:2.2}
x\in L \Leftrightarrow \exists u\in\{0,1\}^{p(\abs{x})}\text{ s.t. }M(x\circ u)=1
     \end{equation}

     Note that because \(M\) is oblivious, we can run it on the trivial input \((x,0^{p(\abs{x})})\)
     to determine the precise head position of \(M\) during its computation on every other input of
     the same length.

     Denote by \(Q\) the set of \(M\)'s possible states and by \Gamma its alphabet. The *snapshot*
     of \(M\)'s execution on some input \(y\) at a particular step \(i\) is the triple
     \(\la a,b,q\ra\in\Gamma\times\Gamma\times Q\) s.t. \(a,b\) are the symbols read by \(M\)'s
     heads from the two tapes and \(q\) is the state \(M\) is in at the \(i\)th step. Clearly the
     snapshot can be encoded as a binary string. Let \(c\) denote the length of this string, which
     is some constant depending upon \(\abs{Q}\) and \(\abs{\Gamma}\)

     #+ATTR_LATEX: :width .5\textwidth :float H
     [[/media/wu/file/stuuudy/notes/images/ComputationalComplexity/4.png]]

     For every \(y\in\{0,1\}^*\), the snapshot of \(M\)'s execution on input \(y\) at the \(i\)th
     step depends on its state in the \((i-1)\)st step and the contents of the current cells of its
     input and work tapes.

     Suppose somebody were to claim the existence of some \(u\) satisfying \(M(x\circ u)=1\) and as
     evidence, present you with the sequence of snapshots that arise from \(M\)'s execution
     on \(x\circ u\). How can you tell that the snapshots present a valid computation that was
     actually performed by \(M\).

     Clearly, it suffices to check that for each \(i\le T(n)\), the snapshot \(z_i\) is correct
     given the snapshot for the previous \(i-1\) steps. However, since the TM can only read/modify
     one bit at a time, to check the correctness of \(z_i\) it suffices to look at only /two/ of the
     previous snapshots. Specifically, to check \(z_i\) we need to only look at the following:
     \(z_{i-1}\), \(y_{\text{inputpos}(i)}\), \(z_{\text{prev}(i)}\). 

     #+ATTR_LATEX: :width .8\textwidth :float H
     [[/media/wu/file/stuuudy/notes/images/ComputationalComplexity/5.png]]

     Here \(y\) is a shorthand
     for \(x\circ u\). \(\text{inputpos}(i)\) denotes the location of \(M\)'s input tape head at
     the \(i\)th step. \(\text{prev}(i)\) is the last step before \(i\) when \(M\)'s head was in the
     same cell on its work tape that it is during step \(i\). The reason this small amount of
     information suffices to check the correctness of \(z_i\) is that the contents of the current
     cell have not been affected between step \(\text{prev}(i)\) and step \(i\).

     Since \(M\) is a deterministic TM, for every triple of values
     to \(z_{i-1},y_{\text{inputpos}(i)}\), \(z_{\text{prev}(i)}\), there is at most one value
     of \(z_i\) that is correct. Thus there is some function \(F\) that maps \(\{0,1\}^{2c+1}\)
     to \(\{0,1\}^c\) s.t. a correct \(z_i\) satisfies
     \begin{equation*}
z_i=F(z_{i-1},z_{\text{prev}(i)},y_{\text{inputpos}(i)})
     \end{equation*}

     Because \(M\) is oblivious, the values \(\text{inputpos}(i)\) and \(\text{prev}(i)\) do not
     depend on the particular input \(i\). These indices can be computed in polynomial-time by
     simulating \(M\) on a trivial input.

     By eqref:eq:2.2 , \(x\in\{0,1\}^{n}\in L\) iff \(M(x\circ u)=1\) for
     some \(u\in\{0,1\}^{p(n)}\). The previous discussion shows this latter condition occurs iff
     there exists a string \(y\in\{0,1\}^{n+p(n)}\) and a sequence of strings
     \(z_1,\dots,z_{T(n)}\in\{0,1\}^c\) (where \(T(n)\) is the number of steps \(M\) takes on inputs
     of length \(n+p(n)\)) satisfying the following four conditions
     1. The first \(n\) bits of \(y\) are equal to \(x\)
     2. The string \(z_1\) encodes the initial snapshot of \(M\). That is, \(z_1\) encodes the
        triple \(\la\rhd,\Box,q_{\start}\ra\).
     3. For every \(i\in\{2,\dots,T(n)\}\), \(z_i=F(z_{i-1},z_{\text{prev}(i)},y_{\text{inputpos}(i)})\).
     4. The last string \(z_{T(n)}\) encodes a snapshot where the machine halts and outputs 1


     The formula \(\varphi_x\) will take variables \(y\in\{0,1\}^{n+p(n)}\)
     and \(z\in\{0,1\}^{cT(n)}\) and will verify that \(y,z\) satisfy the AND of these four
     conditions. Thus \(x\in L\Leftrightarrow\varphi_x\in\SAT\).

     Condition 1 can be expressed as a CNF formula of size \(4n\) . Conditions 2 and 4 each depend
     on \(c\) variables and hence by Proposition ref:lemma2.13 can be expressed by CNF formulae of
     size \(c2^c\). Condition 3, which is an AND of \(T(n)\) conditions each  depending on at most \(3c+1\)
     variables, can be expressedas a CNF formula of size at most \(T(n)(3c+1)2^{3c+1}\). Hence the AND of all
     these conditions can be expressed as a CNF formula of size d(n + T(n)) where d is some constant
     depending only on \(M\). Moreover, this CNF formula can be computedin time polynomial in the running
     time of \(M\).
     #+END_proof

     #+ATTR_LATEX: :options []
     #+BEGIN_lemma
     \(\SAT\le_p3\SAT\)
     #+END_lemma

     #+BEGIN_proof
     Suppose \varphi is a 4CNF. Let \(C\) be a clause of \varphi, say \(C=u_1\vee\baru_2\vee\baru_3\vee u_4\).
     We add a new variable \(z\) to the \varphi and replace \(C\) with the pair
     \(C_1=u_1\vee\baru_2\vee z\) and \(C_2=\baru_3\vee u_4\vee\barz\). If \(C\) is true, then there
     is an assignment to \(z\) that satisfies both \(C_1\) and \(C_2\). If \(C\) is false, then no
     matter what value we assign to \(z\) either \(C_1\) or \(C_2\) will be false.

     For every clause \(C\) of size \(k>3\), we change it into an equivalent pair of clauses \(C_1\)
     of size \(k-1\) and \(C_2\) of size 3.
     #+END_proof

     
**** The Web of Reductions
     #+ATTR_LATEX: :float H
     [[/media/wu/file/stuuudy/notes/images/ComputationalComplexity/6.png]]

     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     \(\INDSET\) is \(\NP\)-complete
     #+END_theorem

     #+BEGIN_proof
     Transform in polynomial time every \(m\)-clause 3CNF formula \varphi into a \(7m\)-vertex graph \(G\)

     #+ATTR_LATEX: :float H
     [[/media/wu/file/stuuudy/notes/images/ComputationalComplexity/7.png]]

     We associate a cluster of 7 vertices in \(G\) with each clause of \varphi. The vertices in a cluster
     associated with a clause \(C\) correspond to the seven possible satisfying partial assignments
     to the three variables on which \(C\) depends. For example, if \(C\)
     is \(\baru_2\vee\baru_5\vee u_7\), then the seven vertices in the cluster associated with \(C\)
     correspond to all partial assignments of the form \(u_1=a,u_2=b,u_3=c\) for a binary
     vector \(\la a,b,c\ra\neq\la1,1,0\ra\). We put an edge between two vertices of \(G\) if they
     correspond to inconsistent partial assignments. In addition, we put edges between every two
     vertices that are in the same cluster

     \varphi is satisfiable iff \(G\) has an independent set of size \(m\)
     #+END_proof

     We let \(\ZOIPROG\) be the set of satisfiable 0/1 integer programs.
     That is, a set of linear inequalities with rational coefficients over
     variables \(u_1,\dots,u_n\) is in \(\ZOIPROG\) if there is an assignment of numbers in \(\{0,1\}\)
     to \(u_1,\dots,u_n\) that satisfies it

     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     \(\ZOIPROG\)is \(\NP\)-complete

     Every CNF formula can be expressed as an integer program by expressing every clause as
     inequality. For example, the clause \(u_1\vee\baru_2\vee\baru_3\) can be expressed by
     \(u_1+(1-u_2)+(1-u_3)\ge1\).
     #+END_theorem

     A *Hamilton path* in a directed graph is a path that visits all vertices exactly once. Let
     \(\dHAMPATH\) denote the set of all directed graphs that contain such a path
     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     \(\dHAMPATH\) is \(\NP\)-complete
     #+END_theorem

     #+BEGIN_proof
     #+ATTR_LATEX: :float H
     [[/media/wu/file/stuuudy/notes/images/ComputationalComplexity/8.png]]

     The graph \(G\) has
     1. \(m\) vertices for each of \(\varphi\)'s clause \(c_1,\dots,c_m\)
     2. a special starting vertex \(v_{\start}\) and ending vertex \(v_{\tend}\)
     3. \(n\) "chains" of \(4m\) vertices corresponding to the \(n\) variables of \varphi . A chain is a
        set of vertices \(v_1,\dots,v_{4m}\) s.t. for every \(i\in[1,4m-1]\), \(v_i\)
        and \(v_{i+1}\) are connected by two edges in both directions


     If \(C\) contains the literal \(u_j\), then we take two neighboring
     vertices \(v_i\), \(v_{i+1}\) in the \(j\)th chain and put an edge from \(v_i\) to \(C\) and
     from \(C\) to \(v_{i+1}\). If \(C\) contains the literal \(\baru_j\) then we construct these
     edges in the opposite direction. When adding these edges, we never "reuse" a
     link \(v_i, v_{i+1}\) in a particular chain and always keep an unused link between every two
     used links.

     
     \(G\in\dHAMPATH\Rightarrow\varphi\in\SAT\). Suppose that \(G\) has an Hamiltonian path \(P\).
     We first note that the path \(P\) must start in \(v_{\start}\) and end at \(v_{\tend}\).
     Furthermore, we claim that \(P\) needs to traverse all the chains in order and, within each
     each chain, traverse it either in left-to-right order or right-to-left order.
     #+END_proof

**** Decision versus Search
     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     label:thm2.18
     Suppose that \(\bP=\NP\). Then for every \(\NP\) language \(L\) and a verifier TM \(M\)
     for \(L\), there is a polynomial-time TM \(B\) that on input \(x\in L\) outputs a certificate
     for \(x\).
     #+END_theorem

     #+BEGIN_proof
     We need to show that if \(\bP=\NP\) then for every polynomial-time TM \(M\) and
     polynomial \(p(n)\), there is a polynomial-time TM \(B\) with the following property: for every
     \(x\in\{0,1\}^n\) if there is \(u\in\{0,1\}^{p(n)}\) s.t. \(M(x,u)=1\) then \(\abs{B(x)}=p(n)\)
     and \(M(x,B(x))=1\)

     We start by showing the theorem for the case of \(\SAT\). In particular, we show that given an
     algorithm \(A\) that decides \(\SAT\), we can come up an algorithm \(B\) that on input a
     satisfiable CNF formula \varphi with \(n\) variables, finds a satisfying assignment for \varphi
     using \(2n+1\) calls to \(A\) and some additional polynomial-time computation.

     We first use \(A\) to check that the input formula is satisfiable. If so, we first
     substitute \(x_1=0\) and then \(x_1=1\) in \varphi and then use \(A\) to decide which of the two is
     satisfiable. Say the first is satisfiable. Then we fix \(x_1=0\). Continuing this way, we end
     up with an assignment

     To solve the search problem for an arbitrary \(\NP\)-language \(L\), we use the fact that the
     reduction of Theorem ref:thm2.10 from \(L\) to \(\SAT\)is actually a Levin reduction. This
     means that we have a polynomial-time computable function \(f\) s.t. we can map a satisfying
     assignment of \(f(x)\) into a certificate for \(x\).
     #+END_proof

     The theorem ref:thm2.18 shows that \(\SAT\) is *downward self-reducible*, which means that
     given an algorithm that solves \(\SAT\) on inputs of length smaller than \(n\) we can
     solve \(\SAT\) on inputs of length \(n\).

**** \textbf{CONP,EXP} and \textbf{NEXP}

     #+ATTR_LATEX: :options []
     #+BEGIN_definition
     label:def2.19
     \(\coNP=\{L:\barL\in\NP\}\)
     #+END_definition

     #+ATTR_LATEX: :options [alternative definition]
     #+BEGIN_definition
     label:def2.20
     For every \(L\subseteq\{0,1\}^*\), we say that \(L\in\coNP\) if there exists a
     polynomial \(p:\N\to\N\) and a polynomial-time TM \(M\) s.t. for every \(x\in\{0,1\}^*\)
     \begin{equation*}
x\in L \Leftrightarrow\forall u\in\{0,1\}^{p(\abs{x})},\; M(x,u)=1
     \end{equation*}
     #+END_definition

     #+ATTR_LATEX: :options []
     #+BEGIN_examplle
     The following language is \(\coNP\)-complete
     \begin{align*}
\TAUTOLOGY=\{\varphi:\varphi\text{ is a tautology}\}
     \end{align*}
     It's clearly in \(\coNP\) by Definition ref:def2.20 (Make \(u\) to be the all possible
     assignments). Modify the Cook-Levin reduction 
     from \(\barL\)(which is in \(\NP\)) to \(\SAT\). For every input \(x\in\{0,1\}^*\) that
     reduction produces a formula \(\varphi_x\) that is satisfiable iff \(x\in\barL\). Now consider
     the formula \(\neg\varphi_x\). It is in \(\TAUTOLOGY\) iff \(x\in L\)
     #+END_examplle

**** \(\EXP\) and \(\NEXP\)
     #+ATTR_LATEX: :options []
     #+BEGIN_theorem
     If \(\EXP\neq\NEXP\) then \(\bP\neq\NP\)
     #+END_theorem

     #+BEGIN_proof
     We prove the contrapositive: Assuming \(\bP=\NP\) we show \(\EXP=\NEXP\).
     Suppose \(L\in\NTIME(2^{n^c})\) and NDTM \(M\) decides it. We claim that the language
     \begin{equation*}
L_{\pad}=\left\{\la x,1^{2^{\abs{x}^c}}\ra:x\in L
\right\}
     \end{equation*}
     is in \(\NP\). Here is an NDTM for \(L_{\pad}\): Given \(y\), first check if there is a
     string \(z\) s.t. \(y=\la z,1^{2^{\abs{z}^c}}\ra\). If not, output 0. If \(y\) is of this form,
     then simulate \(M\) on \(z\) for \(2^{\abs{z}^c}\) steps and output its answer. The running
     time is polynomial in \(\abs{y}\), and hence \(L_{\pad}\in\NP\). Hence if \(\bP=\NP\)
     then \(L_{\pad}\in\bP\). But if \(L_{\pad}\) is in \(\bP\) then \(L\) is in \(\EXP\). To
     determine whether an input \(x\) is in \(L\), we just pad the input and decide whether it is
     in \(L_{\pad}\) using the polynomial-time machine for \(L_{\pad}\)
     #+END_proof

     
**** Exercise
     #+BEGIN_exercise
     label:ex2.11
     Argue at a high level that the following language is \(\NP\)-complete
     \begin{equation*}
\left\{\la\varphi,1^n\ra:\text{ math statement }\varphi
\text{ has a proof of size at most $n$ in the ZF system}
\right\}
     \end{equation*}
     #+END_exercise

     #+BEGIN_proof
     Essential part is to find a reduction.

     Idea: if there are \(n\) derivation rules, then we consider \(n\SAT\)
     #+END_proof
     
     #+BEGIN_exercise
     label:ex2.23
     Prove that \(\bP\subseteq\NP\cap\coNP\)
     #+END_exercise

     #+BEGIN_exercise
     label:ex2.24
     Prove that Definition ref:def2.19 and ref:def2.20 do indeed define the same class
     #+END_exercise

     #+BEGIN_proof
     Suppose \(\coNP=\{L:\barL\in\NP\}\).
     \begin{align*}
x\in L\in\coNP& \Leftrightarrow x\not\in\barL\in\NP\\
& \Leftrightarrow\neg\exists u\in\{0,1\}^{p(\abs{x})} M'(x,u)=1\\
&\Leftrightarrow\forall u\in\{0,1\}^{p(\abs{x})}M'(x,u)\neq1\\
&\Leftrightarrow\forall u\in\{0,1\}^{p(\abs{x})}M(x,u)=1\\
     \end{align*}
     where \(M'\) is a TM for \(\NP\) and \(M\) is a TM for \(\coNP\) by computing the value
     from \(M'\).

     Another direction is the same.
     #+END_proof

*** Space Complexity
    #+ATTR_LATEX: :options [Space-bounded computation]
    #+BEGIN_definition
    Let \(S:\N\to\N\) and \(L\subseteq\{0,1\}^*\). We say that \(L\in\SPACE(s(n))\) if there is a
    constant \(c\) and a TM \(M\) deciding \(L\) s.t. at most \(c\cdot s(n)\) locations on \(M\)'s
    work tapes (excluding the input tape) are ever visited by \(M\)'s head during its computation on
    every input of length \(n\)

    Similarly for \(\NSPACE(s(n))\)
    #+END_definition

