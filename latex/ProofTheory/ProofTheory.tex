% Created 2021-06-05 六 02:23
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\input{preamble.tex}
\usepackage{ebproof}
\def \LJ {\textbf{LJ}}
\def \LK {\textbf{LK}}
\def \LKp {\textbf{LK'}}
\def \LKe {\textbf{LK}_\textbf{e}}
\def \LJp {\textbf{LJ'}}
\def \LKsh {\textbf{LK\#}}
\def \LKs {\textbf{LK}^*}
\author{Gaisi Takeuti}
\date{\today}
\title{Proof Theory}
\hypersetup{
 pdfauthor={Gaisi Takeuti},
 pdftitle={Proof Theory},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.1 (Org mode 9.3)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

\section{First Order Predicate Calculus}
\label{sec:org80d4d63}
In this chapter we shall present Gentzen's formulation of the first order predicate
calculus \(\LK\) (logistischer klassischer Kalkül). Intuitionisitic logic is known as \(\LJ\)
(logistischer intuitionistischer Kalkül) 
\subsection{Formalization of statements}
\label{sec:org07ab912}

\begin{definition}[]
\textbf{Terms} are defined inductively as follows:
\begin{enumerate}
\item Every individual constant is a term
\item Every free variable is a term
\item If \(f^i\) is a function constant with \(i\) argument-places and \(t_1,\dots,t_i\) are terms,
then \(f^i(t_1,\dots,t_i)\) is a term
\item Terms are only those expressions obtained by 1-3.
\end{enumerate}
\end{definition}


\begin{definition}[]
\textbf{Formulas} are defined inductively as:
\begin{enumerate}
\setcounter{enumi}{2}
\item If \(A\) is a formula, \(a\) is a free variable and \(x\) is a bound
variable not occurring in \(A\), then \(\forall xA'\) and \(\exists xA'\) are
formulas, where \(A'\) is the expression obtained from \(A\) by writing
\(x\) in place of \(a\) at each occurrence of \(a\) in \(A\)
\end{enumerate}
\end{definition}


\begin{definition}[]
Let \(A\) be an expression, let \(\tau_1,\dots,\tau_n\) be distinct primitive
symbols, and let \(\sigma_1,\dots,\sigma_n\) be any symbols. By
\begin{equation*}
\left(
A\frac{\tau_1,\dots,\tau_n}{\sigma_1,\dots,\sigma_n}
\right)
\end{equation*}
we mean the expression obtained from \(A\) by writing
\(\sigma_1,\dots,\sigma_n\) in place of \(\tau_1,\dots,\tau_n\) respectively
at each occurrence of \(\tau_1,\dots,\tau_n\). Such an operation is called
the \textbf{(simultaneous) replacement of} \((\tau_1,\dots,\tau_n)\) \textbf{by}
\((\sigma_1,\dots,\sigma_n)\) \textbf{in} \(A\).
\end{definition}

\begin{proposition}[]
\begin{enumerate}
\item If \(A\) contains none of \(\tau_1,\dots,\tau_n\), then
\begin{equation*}
\left(
A\frac{\tau_1,\dots,\tau_n}{\sigma_1,\dots,\sigma_n}
\right)
\end{equation*}
is \(A\) itself
\item If \(\sigma_1,\dots,\sigma_n\) are distinct primitive symbols, then
\begin{equation*}
\left(\left(
A\frac{\tau_1,\dots,\tau_n}{\sigma_1,\dots,\sigma_n}
\right)\frac{\sigma_1,\dots,\sigma_n}{\theta_1,\dots,\theta_n}\right)
\end{equation*}
is identical with
\begin{equation*}
\left(
A\frac{\tau_1,\dots,\tau_n}{\theta_1,\dots,\theta_n}
\right)
\end{equation*}
\end{enumerate}
\end{proposition}

\begin{definition}[]
\begin{enumerate}
\item Let \(A\) be a formula and \(t_1,\dots,t_n\) be terms. If there is a
formula \(B\) and \(n\) distinct free variables \(b_1,\dots,b_n\) s.t.
\(A\) is
\begin{equation*}
\left(
B\frac{b_1,\dots,b_n}{t_1,\dots,t_n}
\right)
\end{equation*}
then for each \(i(1\le i\le n)\) the occurrences of \(t_1\) resulting from
the above replacement are said to be \textbf{indicated} in \(A\), and this fact is
also expressed by writing \(B\) as \(B(b_1,\dots,b_n)\) and \(A\) as \(B(t_1,\dots,t_n)\)
\item A term \(t\) is \textbf{fully indicated} in \(A\), or every occurrence of \(t\) in
\(A\) is indicated, if every occurrence of \(t\) is obtained by such a replacement
\end{enumerate}
\end{definition}

\begin{proposition}[]
If \(A\) is a formula (where \(a\) is not necessarily fully indicated) and
\(x\) is a bound variable not occurring in \(A(a)\), then \(\forall xA(x)\) and
\(\exists xA(x)\) are formulas
\end{proposition}


\subsection{Formal proofs and related concepts}
\label{sec:org5d24d4b}
\begin{definition}[]
An \textbf{inference} is an expression of the form

\begin{equation*}
\begin{prooftree}[center=false]
\hypo{S_1}
\infer1{S}
\end{prooftree}\text{ or }
\begin{prooftree}[center=false]
\hypo{S_1}
\hypo{S_2}
\infer2{S}
\end{prooftree}
\end{equation*}
where \(S_1,S_2\) and \(S\) are sequents. \(S_1\) and \(S_2\) are called the
\textbf{upper sequents} and \(S\) is called the \textbf{lower sequent} of the inference
\end{definition}

\begin{definition}[]
For arbitrary \(\Gamma\) and \(\Delta\) in the above notation, \(\Gamma\to\Delta\) is called a
\textbf{sequent}. \(\Gamma\) and \(\Delta\) are called the \textbf{antecedent} and \textbf{succedent},
respectively, of the sequent and each formula in \(\Gamma\) and \(\Delta\) is called a
\textbf{sequent-formula} 
\end{definition}

Structural rules
\begin{enumerate}
\item \textbf{Weakening}:
\begin{equation*}
\text{left: }
\begin{prooftree}
\hypo{\Gamma\to\Delta}
\infer1{D,\Gamma\to\Delta}
\end{prooftree};\quad\text{right: }
\begin{prooftree}
\hypo{\Gamma\to\Delta}
\infer1{\Gamma\to\Delta,D}
\end{prooftree}
\end{equation*}
\(D\) is called the \textbf{weakening formula}
\item \textbf{Contraction}:
\begin{equation*}
\text{left: }
\begin{prooftree}
\hypo{D,D,\Gamma\to\Delta}
\infer1{D,\Gamma\to\Delta}
\end{prooftree}\quad\text{ right: }
\begin{prooftree}
\hypo{\Gamma\to\Delta,D,D}
\infer1{\Gamma\to\Delta,D}
\end{prooftree}
\end{equation*}
\item \textbf{Exchange}
\begin{equation*}
\text{left: }
\begin{prooftree}
\hypo{\Gamma,C,D,\Pi\to\Delta}
\infer1{\Gamma,D,C,\Pi\to\Delta}
\end{prooftree}\quad\text{ right: }
\begin{prooftree}
\hypo{\Gamma\to\Delta,C,D,\Lambda}
\infer1{\Gamma\to\Delta,D,C,\Lambda}
\end{prooftree}
\end{equation*}
\end{enumerate}


We will refer to these three kinds of inferences as "weak inferences",
while all others will be called "strong inferences"
\begin{enumerate}
\setcounter{enumi}{3}
\item \textbf{Cut}
\begin{equation*}
\begin{prooftree}[center=false]
\hypo{\Gamma\to\Delta,D}
\hypo{D,\Pi \to\Lambda}
\infer2{\Gamma,\Pi\to\Delta,\Lambda}
\end{prooftree}
\end{equation*}
\(D\) is called the \textbf{cut formula} of this instance
\end{enumerate}


Logical rules
\begin{enumerate}
\item \begin{equation*}
\neg:\text{left: }
\begin{prooftree}
\hypo{\Gamma\to\Delta,D}
\infer1{\neg D,\Gamma\to\Delta}
\end{prooftree};\quad
\neg:\text{right: }
\begin{prooftree} 
\hypo{D,\Gamma\to\Delta}
\infer1{\Gamma\to\Delta,\neg D}
\end{prooftree}
\end{equation*}
\(D\) and \(\neg D\) are called the \textbf{auxiliary formula} and the \textbf{principal
formula} respectively, of this inference
\item \begin{align*}
&
\begin{prooftree}
\hypo{C,\Gamma\to\Delta}
\infer1[\(\wedge\)left]{C\wedge D,\Gamma\to\Delta}
\end{prooftree}\quad\text{ and }\quad
\begin{prooftree}
\hypo{D,\Gamma\to\Delta}
\infer1[\(\wedge\)left]{C\wedge D,\Gamma\to\Delta}
\end{prooftree}\\
&
\begin{prooftree}[center=false]
\hypo{\Gamma\to\Delta,C}
\hypo{\Gamma\to\Delta,D}
\infer2[\(\wedge\)right]{\Gamma\to\Delta,C\wedge D}
\end{prooftree}
\end{align*}
\(C\) and \(D\) are called the auxiliary formulas and \(C\wedge D\) is
called the principal formula of this inference

\item \begin{align*}
&
\begin{prooftree}[center=false]
\hypo{C,\Gamma\to\Delta}
\hypo{D,\Gamma\to\Delta}
\infer2[\(\vee\)left]{C\vee D,\Gamma\to\Delta}
\end{prooftree}\\&
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta,C}
\infer1[\(\vee\)right]{\Gamma\to\Delta,C\vee D}
\end{prooftree}\quad\text{ and }\quad
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta,D}
\infer1[\(\vee\)right]{\Gamma\to\Delta,C\vee D}
\end{prooftree}
\end{align*}
\(C\) and \(D\) are called the auxiliary formulas and \(C\vee D\) the
principal formula of this inference
\item \begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta,C}
\hypo{D,\Pi\to \Lambda}
\infer2[\(\supset\)left]{C\supset D,\Gamma,\Pi\to\Delta,\Lambda}
\end{prooftree}\hspace{1cm}
\begin{prooftree}%[center=false]
\hypo{C,\Gamma\to\Delta,D}
\infer1[\(\supset\)right]{\Gamma\to\Delta,C\supset D}
\end{prooftree}
\end{equation*}
\(C\) and \(D\) are called the auxiliary formulas and \(C\supset D\) the
principal formula
\end{enumerate}


1-4 are called \textbf{propositional inferences}
\begin{enumerate}
\setcounter{enumi}{4}
\item \begin{equation*}
\begin{prooftree}%[center=false]
\hypo{F(t),\Gamma\to\Delta}
\infer1[\(\forall\)left]{\forall xF(x),\Gamma\to\Delta}
\end{prooftree}\hspace{1cm}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta,F(a)}
\infer1[\(\forall\)right]{\Gamma\to\Delta,\forall xF(x)}
\end{prooftree}
\end{equation*}
where \(t\) is an arbitrary term, and \(a\) does not occur in the lower
sequent. \(F(t)\) and \(F(a)\) are called the auxiliary formulas and
\(\forall xF(x)\) the principal formula. The \(a\) in \(\forall\)right is called
the \textbf{eigenvariable} of this inference
\end{enumerate}


In \(\forall\)right all occurrences of \(a\) in \(F(a)\) are indicated. In
\(\forall\)left, \(F(t)\) and \(F(x)\) are
\begin{equation*}
\left(F(a)\frac{a}{t}
\right)\quad\text{ and }\quad
\left(F(a)\frac{a}{t}
\right)
\end{equation*}
respectively, so not every \(t\) in \(F(t)\) is necessarily indicated

\begin{enumerate}
\setcounter{enumi}{5}
\item \begin{equation*}
\begin{prooftree}%[center=false]
\hypo{F(a),\Gamma\to\Delta}
\infer1[\(\exists\)left]{\exists xF(x),\Gamma\to\Delta}
\end{prooftree}\hspace{1cm}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta,F(t)}
\infer1[\(\exists\)right]{\Gamma\to\Delta,\exists xF(x)}
\end{prooftree}
\end{equation*}
where \(a\) does not occur in the lower sequent, and \(t\) is an arbitrary
term

\(F(a)\) and \(Ft\) are called the auxiliary formulas and \(\exists xF(x)\) the
principal formula. The \(a\) in \(\exists\)left is called the
eigenvariable of this inference
\end{enumerate}


In \(\exists\)left \(a\) is fully indicated

5 and 6 are called the \textbf{quantifier inferences}. The condition, that the
eigenvariable must not occur in the lower sequent in \(\forall\)right and
\(\exists\)left is called the \textbf{eigenvariable condition}

A sequent of the form \(A\to A\) is called an \textbf{initial sequent} or axiom

\begin{definition}[]
A \textbf{proof} \(P\) (in \(\LK\)), or \textbf{\(\LK\)-proof}, is a tree of sequents
satisfying the following conditions
\begin{enumerate}
\item The topmost sequents of \(P\) are initial sequents
\item Every sequent in \(P\) except the lowest one is an upper sequent of an
inference whose lower sequent is also in \(P\)
\end{enumerate}
\end{definition}

\begin{definition}[]
\begin{enumerate}
\item A sequence of sequents in a proof \(P\) is called a \textbf{thread} (of \(P\)) if
the following conditions are satisfied
\begin{enumerate}
\item The sequence begins with an initial sequent and ends with the end-sequent
\item Every sequent in the sequence except the last is an upper sequent of an
inference, and is immediately followed by the lower sequent of this inference
\end{enumerate}
\item Let \(S_1,S_2\)and \(S_3\) be sequents in a proof \(P\). We say \(S_1\)
is \textbf{above} \(S_2\)or \(S_2\) is \textbf{below} \(S_1\) if there is a thread
containing both \(S_1\)and \(S_2\) where \(S_1\) appears before
\(S_2\). If \(S_1\)is above \(S_2\)and \(S_2\) is above \(S_3\), we say
\(S_2\) is \textbf{between} \(S_1\) and \(S_3\)
\item An inference in \(P\) is said to be \textbf{below a sequent} \(S\) if its lower
sequent is below \(S\)
\item Let \(P\) be a proof. A part of \(P\) which itself is a proof is called a
\textbf{subproof} of \(P\). For any sequent \(S\) in \(P\), that part of \(P\)
which consists of all sequents which are either \(S\)itself or which occur
above \(S\)is called a subproof of \(P\) (with end-sequent \(S\))
\item Let \(P_0\) be a proof of the form
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{}
\ellipsis{}{\Gamma\to\Theta}
\ellipsis{(*)}{}
\end{prooftree}
\end{equation*}
where (*) denotes the part of \(P_0\) under \(\Gamma\to\Theta\), and let
\(Q\) be a proof ending with \(\Gamma,D\to\Theta\). By a copy of \(P_0\) from
\(Q\) we mean a proof \(P\) of the form
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{}
\ellipsis{Q}{\Gamma,D\to\Theta}
\ellipsis{(**)}{}
\end{prooftree}
\end{equation*}
where \((**)\) differs from \((*)\) only in that for each sequent in \((*)\),
say \(\Gamma\to\Lambda\), the corresponding sequent in \((**)\) has the
form \(\Pi,D\to\Lambda\).
\item Let \(S(a)\) or \(\Gamma(a)\to\Delta(a)\), denote a sequent of the form
\(A_1(a),\dots,A_m(a)\to B_1(a),\dots,B_n(a)\). Then \(S(t)\), or
\(\Gamma(t)\to\Delta(t)\), denotes the sequent
\end{enumerate}
\(A_1(t),\dots,A_m(t)\to B_1(t),\dots,B_n(t)\)
\end{definition}

\begin{definition}[]
A proof in \(\LK\) is called \textbf{regular} if it satisfies the condition that all
eigenvariables are distinct from one another and if a free variable \(a\)
occurs as an eigenvariable in a sequent \(S\) of the proof, then \(a\) occurs
only in sequents above \(S\)
\end{definition}

\begin{lemma}[]
\begin{enumerate}
\item Let \(\Gamma(a)\to\Delta(a)\) be an (\(\LK\)-)provable sequent in which \(a\)
is fully indicated, and let \(P(a)\) be a proof of \(\Gamma(a)\to\Delta(a)\).
Let \(b\) be a free variable not occurring in \(P(a)\). Then the tree
\(P(b)\), obtained from \(P(a)\) by replacing \(a\) by \(b\) at each
occurrence of \(a\) in \(P(a)\), is also a proof and its end-sequent is \(\Gamma(b)\to\Delta(b)\)
\item For an arbitrary \(\LK\)-proof there exists a regular proof of the same
end-sequent. Moreover, the required proof is obtained from the original
proof simply by replacing free variables
\end{enumerate}
\end{lemma}

\begin{proof}
\begin{enumerate}
\item By induction on the number of inference in \(P(a)\). If \(P(a)\) consists
of simply an initial sequent \(A(a)\to A(a)\), then \(P(b)\) consists of the
sequent \(A(b)\to A(b)\).

Suppose that our proposition holds for proofs containing at most \(n\)
inferences and suppose that \(P(a)\) contains \(n+1\) inferences. We treat
the possible cases according to the last inferences in \(P(a)\). Since
other cases can be treated similarly, we consider only the case where the
last inference, say \(J\), is a \(\forall\)right. Suppose the
eigenvariable of \(J\) is \(a\), and \(P(a)\) is of the form
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{}
\ellipsis{\(Q(a)\)}{\Gamma\to\Lambda,A(a)}
\infer1[\(J\)]{\Gamma\to\Lambda,\forall xA(x)}
\end{prooftree}
\end{equation*}
where \(Q(a)\) is the subproof of \(P(a)\) ending with
\(\Gamma\to\Lambda,A(a)\). \(a\) doesnt occur in \(\Gamma\), \(\Lambda\) or \(A(x)\). By the
induction hypotheses the result of replacing all \(a\)'s  in \(Q(a)\) by
\(b\) is a proof whose end-sequent is \(\Gamma\to\Lambda,A(b)\). \(\Gamma\) and \(\Lambda\)
contain no \(b\)'s. Thus we can apply a \(\forall\)right to this sequent
using \(b\) as its eigenvariable
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{}
\ellipsis{\(Q(b)\)}{\Gamma\to\Lambda,A(b)}
\infer1[]{\Gamma\to\Lambda,\forall xA(x)}
\end{prooftree}
\end{equation*}
and so \(P(b)\) is a proof ending with \(\Gamma\to\Lambda,\forall xA(x)\). If
\(a\) is not the eigenvariable of \(J\), \(P(a)\) is of the form
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{}
\ellipsis{\(Q(a)\)}{\Gamma(a)\to\Lambda(a),A(a,c)}
\infer1{\Gamma(a)\to\Lambda(a),\forall xA(a,x)}
\end{prooftree}
\end{equation*}
By the induction hypothesis the result of replacing all \(a\)'s in
\(Q(a)\) by \(b\)is a proof and its end-sequent is
\(\Gamma(b)\to\Lambda(b),A(b,c)\)

Since by assumption \(b\) doesn't occur in \(P(a)\), \(b\) is not \(c\)
and so we can apply a \(\forall\)right to this sequent, with \(c\) as its eigenvariable

\item By mathematical induction on the number \(l\) of applications of
\(\forall\)right and \(\exists\)left in a given proof \(P\). If \(l=0\)
then take \(P\) itself. Otherwise, \(P\) can be represented in the form
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{P_1\quad P_2\dots P_k}
\ellipsis{(*)}{S}
\end{prooftree}
\end{equation*}
where \(P_i\) is a subproof of \(P\) of the form
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{}
\ellipsis{}{\Gamma_i\to\Delta_i,F_i(b_i)}
\infer1[\(I_i\)]{\Gamma_i\to\Delta_i,\forall y_iF_i(y_i)}
\end{prooftree}
\quad\text{ or }\quad
\begin{prooftree}%[center=false]
\hypo{}
\ellipsis{}{F_i(b_i),\Gamma_i\to\Delta_i}
\infer1[\(I_i\)]{\exists y_iF_i(y_i),\Gamma_i\to\Delta_i}
\end{prooftree}      
\end{equation*}
and \(I_i\) is a lowermost \(\forall\)right or \(\exists\)left in \(P\)

Let us deal with the case where \(I_i\) is \(\forall\)right. \(P_i\) has
fewer applications of \(\forall\)right or \(\exists\)left than \(P\), so
by the induction hypothesis there is a regular proof \(P_i'\) of
\(\Gamma_i\to\Delta_i,F_i(b_i)\). Note that no free variable in
\(\Gamma_i\to\Delta_i,F_i(b_i)\) (including \(b_i\)) is used as an
eigenvariable in \(P_i'\). Suppose \(c_1,\dots,c_m\) are all the
eigenvariables in all the \(P_i\)'s which occur in \(P\) above
\(\Gamma_i\to\Delta_i,\forall y_iF_i(y_i), i=1,\dots,k\). Then change
\(c_1,\dots,c_m\) to \(d_1,\dots,d_m\) respectively, where
\(d_1,\dots,d_m\) are the first \(m\) variables which occur neither in
\(P\) nor in \(P_i\)'. If \(b_i\) occurs in \(P\) below
\(\Gamma_i\to\Delta_i,\forall y_iF_i(y_i)\) then change it to \(d_{m+i}\)

Let \(P_i''\) be the proof which is obtained from \(P_i'\) by the above
replacement of varaibles. Then \(P_1'',\dots,P_k''\) are each regular
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{P_1''\dots
\begin{prooftree}%[center=false]
\hypo{P_i''}
\infer1{\Gamma_i\to\Delta_i,\forall y_iF_i(y_i)}
\end{prooftree}\dots P_n''}
\ellipsis{(*)}{S}
\end{prooftree}
\end{equation*}
\end{enumerate}
\end{proof}

From now on we will assume that we are dealing with regular proofs whenever
convenient

\begin{lemma}[]
Let \(t\) be an arbitrary term. Let \(\Gamma(a)\to \Delta(a)\) be a provable (in \(\LK\))
sequent in which \(a\) is fully indicated, and let \(P(a)\) be a proof ending
with \(\Gamma(a)\to \Delta(a)\) in which \textbf{every eigenvariable is different from \(a\) and
not contained in \(t\)}. Then \(P(t)\) is a proof whose end-sequent is
\(\Gamma(t)\to \Delta(t)\)
\end{lemma}

\begin{lemma}[]
Let \(t\) be an arbitrary term. Let \(\Gamma(a)\to \Delta(a)\) be a provable (in \(\LK\))
sequent in which \(a\) is fully indicated, and let \(P(a)\) be a proof of
\(\Gamma(a)\to \Delta(a)\). Let \(P'(a)\) be a proof obtained from \(P(a)\) by changing
eigenvariables in such a way that in \(P'(a)\) every eigenvariable is
different from \(a\) and not contained in \(t\). Then \(P'(t)\) is a proof of
\(\Gamma(t)\to \Delta(t)\)
\end{lemma}

\begin{proposition}[]
Let \(t\) be an arbitrary term and \(S(a)\) a provable sequent in which \(a\)
is fully indicated. Then \(S(t)\) is also provable
\end{proposition}

\begin{proposition}[]
\label{prop2.14}
If a sequent is provable, then it is provable with a proof in which all the
initial sequents consist of atmoic formulas. Furthermore, if a sequent is
provable without cut, then it is provable without cut with a proof of the
above sort
\end{proposition}

\begin{proof}
It suffices to show that for an arbitrary formula \(A\), \(A\to A\) is
provable without cut, starting with initial sequents consisting of atomic formulas.
\end{proof}

\begin{definition}[]
Two formulas \(A\) and \(B\) are \textbf{alphabetical variants} if for some
\(x_1,\dots,x_n,y_1,\dots,y_n\)
\begin{equation*}
\left(A\frac{x_1,\dots,x_n}{z_1,\dots,z_n}
\right)
\end{equation*}
is
\begin{equation*}
\left(
B\frac{y_1,\dots,y_n}{z_1,\dots,z_n}
\right)
\end{equation*}
where \(z_1,\dots,z_n\) are bound variables occurring neither in \(A\) nor in
\(B\). The fact that \(A\) and \(B\) are alphabetical variants will be
expressed by \(A\sim B\)
\end{definition}

\subsection{A formulation of intuitionistic predicate calculus}
\label{sec:org036dc2b}
\begin{definition}[]
We can formalize the intuitionistic predicate calculus as a subsystem of
\(\LK\) which we call \(\LJ\) following Gentzen (\(\bJ\) stands for
"intuitionistic"). \(\LJ\)is obtained from \(\LK\) by modifying it as follows
\begin{enumerate}
\item A sequent in \(\LJ\) is of the form \(\Gamma \to \Delta\) where \(\Delta\) consists of at most
one formula
\item Inferences in \(\LJ\) are those obtained from those in \(\LK\) by imposing
the restriction that the succedent of each upper and lower sequent
consists of at most one formula; thus there are no inferences in
\(\LJ\)corresponding to contraction right or exchange right
\end{enumerate}
\end{definition}

\begin{proposition}[]
If a sequent \(S\) of \(\LJ\) is provable in \(\LJ\), then it is also
provable in \(\LK\)
\end{proposition}

\subsection{Axiom systems}
\label{sec:org3ea3139}
\begin{definition}[]
The basic system is \(\LK\)
\begin{enumerate}
\item A finite or infinite set \(\cala\) of sentences is called an \textbf{axiom system},
and each of these sentences is called an \textbf{axiom} of \(\cala\). Sometimes an
axiom system is called a \textbf{theory}
\item A finite (possibly empty) sequence of formulas consisting only of axioms
of \(\cala\) is called an \textbf{axiom sequence} of \(\cala\)
\item If there exists an axiom sequence \(\Gamma_0\) of \(\cala\) s.t.
\(\Gamma_0,\Gamma\to\Delta\) is \(\LK\)-provable, then \(\Gamma \to \Delta\) is
said to be \textbf{provable from} \(\cala\) (in \(\LK\)). We express this by \(\cala,\Gamma\to\Delta\)
\item \(\cala\) is \textbf{inconsistent} (with \(\LK\)) if the empty sequent \(\to\) is
provable from \(\cala\) (in \(\LK\))
\item If all function constants and predicate constants in a formula \(A\) occur
in \(\cala\), then \(A\) is said to be \textbf{dependent on} \(\cala\)
\item A sentence \(A\) is \textbf{consistent} if the axiom system \(\{A\}\) is consistent
\item \(\LK_{\cala}\) is the system obtained from \(\LK\) by adding \(\to A\) as
initial sequents for all \(A\) in \(\cala\)
\end{enumerate}
\end{definition}

\begin{proposition}[]
Let \(\cala\) be an axiom system. Then the following are equivalent
\begin{enumerate}
\item \(\cala\) is inconsistent (with \(\LK\))
\item for every formula \(A\), \(A\) is provable from \(\cala\)
\item for some formula \(A\), \(A\)and \(\neg A\) are both provable from \(\cala\)
\end{enumerate}
\end{proposition}

\begin{proof}
\(1\leftrightarrow 2\), \(2\leftrightarrow3\). \(\to A\vee B\) and
\(\to \neg A\vee B\) implies \(\to B\)
\end{proof}

\begin{proposition}[]
Let \(\cala\) be an axiom system. Then a sequent \(\Gamma\to \Delta\) is
\(\LK_{\cala}\)-provable iff \(\Gamma\to\Delta\) is provable from \(\cala\)
(in \(\LK\))
\end{proposition}

\begin{corollary}[]
An axiom system \(\cala\) is consistent (with \(\LK\)) iff \(\LK_{\cala}\) is consistent
\end{corollary}

These definitions and the propositions hold also for \(\LJ\)

\subsection{The cut-elimination theroem}
\label{sec:org85ca75a}
\begin{theorem}[the cut-elimination theroem: Gentzen]
\label{thm5.1}
If a sequent is \((\LK)\)-provable, then it is \((\LK)\)-provable without a cut
\end{theorem}

Let \(A\)be a formula. An inference of the following form is called a \textbf{mix}
(w.r.t. \(A\)):
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta}
\hypo{\Pi\to\Lambda}
\infer2[\(A\)]{\Gamma,\Pi^* \to \Delta^*, \Lambda}
\end{prooftree}
\end{equation*}
where both \(\Delta\) and \(\Pi\) contain the formula \(A\), and \(\Delta^*\) and \(\Pi^*\) are
obtained from \(\Delta\) and \(\Pi\) respectively by deleting all the occurrences of \(A\)
in them. We call \(A\) the mix formula of this inference.

Let's call the system which is obtained from \(\LK\) by replacing the cut
rule by the mix rule, \(\LKs\).

\begin{lemma}[]
\(\LK\) and \(\LKs\) are equivalent, that is, a sequent \(S\) is
\(\LK\)-provable iff \(S\) is \(\LKs\)-provable
\end{lemma}

\begin{theorem}[]
If a sequent is provable in \(\LKs\), then it's provable in \(\LKs\) without
a mix
\end{theorem}

\begin{lemma}[]
If \(P\) is a proof of \(S\) (in \(\LKs\)) which contains (only) one mix,
occurring as the last inference, then \(S\) is provable without a mix
\end{lemma}

The \textbf{grade} of a formula \(A\) (denoted by \(g(A)\)) is the number of logical
symbols contained in \(A\). The grade of a mix is the grade of the mix
formula. When a proof \(P\) has a mix as the last inference, we define the
grade of \(P\) (denoted by \(g(P)\)) to be the grade of this mix.

Let \(P\) be a proof which contains  a mix only as the last inference
\begin{equation*}
J\;\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta}
\hypo{\Pi \to \Lambda}
\infer2[\((A)\)]{\Gamma,\Pi^* \to \Delta^*,\Lambda}
\end{prooftree}
\end{equation*}
We refer to the left and right upper sequents as \(S_1\) and \(S_2\) and to
the lower sequent as \(S\). We call a thread in \(P\) a \textbf{left (right) thread}
if it contains the left (right) upper sequent of the mix \(J\). The \textbf{rank} of a
thread \(\calf\) in \(P\) is defined as follows: if \(\calf\) is a left
(right) thread, then the rank of \(\calf\) is the number consecutive
sequents, counting upward from the left (right) upper sequent of \(J\), that
contains the mix formula in its succedent (antecedent). The rank of a thread
\(\calf\) in \(P\) is denoted by \(\rank(\calf;P)\). We define
\begin{equation*}
\rank_l(P)=\max_{\calf}(\rank(\calf;P))
\end{equation*}
where \(\calf\) ranges over all the left threads in \(P\), and
\begin{equation*}
\rank_r(P)=\max_{\calf}(\rank(\calf;P))
\end{equation*}
where \(\calf\) ranges over all the right threads in \(P\). The rank of
\(P\), \(\rank(P)\), is defined as
\begin{equation*}
\rank(P)=\rank_l(P)+\rank_r(P)
\end{equation*}
Note that \(\rank(P)\ge 2\)

\begin{proof}
We prove the Lemma by double induction on the grade \(g\) and rank \(r\) of
the proof \(P\) (i.e. transfinite induction on \(\omega\cdot g+r\)). We
divide the proof into two main cases, namely \(r=2\) and \(r>2\)

\begin{enumerate}
\item \(r=2\), \(\rank_l(P)=\rank_r(P)=1\)
\begin{enumerate}
\item The left upper sequent \(S_1\) is an initial sequent. In this case we
may assume \(P\) is of the form
\begin{equation*}
J\;\begin{prooftree}%[center=false]
\hypo{A\to A}
\hypo{\Pi\to \Lambda}
\infer2{A,\Pi^*\to\Lambda}
\end{prooftree}
\end{equation*}
We can obtain the lower sequent without a mix
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Pi\to\Lambda}
\infer1{\text{some exchanges}}
\infer1{A,\dots,A,\Pi^*\to\Lambda}
\infer1{\text{some contractions}}
\infer1{A,\Pi^*\to\Lambda}
\end{prooftree}
\end{equation*}
\item The right upper sequent \(S_2\) is an initial sequent.
\item Neither \(S_1\) nor \(S_2\) is an initial sequent, and \(S_1\) is the
lower sequent of a structural inference \(J_1\). Since
\(\rank_l(P)=1\), the formula \(A\) cannot appear in the succedent of
the upper sequent of \(J_1\). Hence
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta_1}
\infer1[\(J_1\)]{\Gamma\to\Delta_1,A}
\hypo{\Pi\to\Lambda}
\infer2[\(J\)]{\Gamma,\Pi^*\to\Delta_1,\Lambda}
\end{prooftree}
\end{equation*}
where \(\Delta_1\) doesn't contain \(A\). We can eliminate the mix as
follows
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta_1}
\infer1{\text{some weakenings}}
\infer1{\Pi^*,\Gamma\to\Delta_1,\Lambda}
\infer1{\text{some exchanges}}
\infer1{\Gamma,\Pi^*\to\Delta_1,\Lambda}
\end{prooftree}
\end{equation*}
\item None of 1.1-1.3 holds but \(S_2\) is the lower sequent of a structural
inference. Similarly
\item Both \(S_1\)and \(S_2\)are the lower sequents of logical inferences. In
this case, since \(\rank_l(P)=\rank_r(P)=1\), the mix formula on each
side must be the principal formula of the logical inference. We use
induction on the grade, distinguishing several cases according to the
outermost logical symbol of \(A\)
\begin{enumerate}
\item The outermost logical symbol of \(A\) is \(\wedge\)
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta_1,B}
\hypo{\Gamma\to\Delta_1,C}
\infer2{\Gamma\to\Delta_1,B\wedge C}
\hypo{B,\Pi_1\to\Lambda}
\infer1{B\wedge C,\Pi_1\to \Lambda}
\infer2[(\(B\wedge C\))]{\Gamma,\Pi_1\to\Delta_1,\Lambda}
\end{prooftree}
\end{equation*}
where by assumption none of the proofs ending with
\(\Gamma\to\Delta_1,B\);\(\Gamma\to\Delta_1,C\) or
\(B,\Pi_1\to\Lambda\) contain a mix. Consider the following
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta_1,B}
\hypo{B,\Pi_1\to\Lambda}
\infer2[\((B)\)]{\Gamma,\Pi_1''\to\Delta_1'',\Lambda}
\end{prooftree}
\end{equation*}
This proof contains only one mix, a mix that occurs as its last
inference. Furthermore the grade of the mix formula \(B\) is less
than \(g(A)\). So by induction hypothesis we can obtain a proof
which contains no mixes and whose end-sequent is
\(\Gamma,\Pi_1''\to\Delta_1'',\Lambda\). From this we can obtain a proof
without a mix with end-sequent \(\Gamma,\Pi_1\to\Delta_1,\Lambda\)
\item The outermost logical symbol of \(A\) is \(\forall\)
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta_1,F(a)}
\infer1{\Gamma\to\Delta_1,\forall xF(x)}
\hypo{F(t),\Pi_1\to\Lambda}
\infer1{\forall xF(x),\Pi_1\to\Lambda}
\infer2{\Gamma,\Pi_1\to\Delta_1,\Lambda}
\end{prooftree}
\end{equation*}
(\(a\) being fully indicated in \(F(a)\)). By the eigenvariable
condition, \(a\) does not occur in \(\Gamma,\Delta_1\) or \(F(x)\). Since
by assumption the proof ending with \(\Gamma\to\Delta_1, F(a)\)
contains no mix, we can obtain a proof without a mix, ending with
\(\Gamma\to\Delta_1,F(t)\). Consider now
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta_1,F(t)}
\hypo{F(t),\Pi_1\to\Lambda}
\infer2[\((F(t))\)]{\Gamma,\Pi_1'''\to\Delta_1''',\Lambda}
\end{prooftree}
\end{equation*}
\end{enumerate}
\end{enumerate}
\item \(r>2\), i.e., \(\rank_l(P)>1\) and/or \(\rank_r(P)>1\)

The induction hypothesis is that every proof \(Q\) which contains a mix
only as the last inference, and which satisfies either \(g(Q)<g(P)\), or
\(g(Q)=g(P)\) and \(\rank(Q)<\rank(P)\), we can eliminate the mix
\begin{enumerate}
\item \(\rank_r(P)>1\)
\begin{enumerate}
\item \(\Gamma\) or \(\Delta\) (in \(S_1\)) contains \(A\). Construct a proof as follows
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{}
\ellipsis{}{\Pi\to\Lambda}
\infer1{\text{exchanges/contractions}}
\infer1{A,\Pi^*\to\Lambda}
\infer1{\text{weakenings/exchanges}}
\infer1{\Gamma,\Pi^*\to\Delta^*,\Lambda}
\end{prooftree}\quad
\begin{prooftree}%[center=false]
\hypo{}
\ellipsis{}{\Gamma\to\Delta}
\infer1{\text{exchanges/contractions}}
\infer1{\Gamma\to\Delta^*,A}
\infer1{\text{weakenings/exchanges}}
\infer1{\Gamma,\Pi^*\to\Delta^*,\Lambda}
\end{prooftree}
\end{equation*}

\item \(S_2\) is the lower sequent of an inference \(J_2\), where \(J_2\)
is not a logical inference whose principal formula is \(A\). The
last part of \(P\) looks like this
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta}
\hypo{\Phi\to\Psi}
\infer1[\(J_2\)]{\Pi\to\Lambda}
\infer2{\Gamma,\Pi^*\to\Delta^*,\Lambda}
\end{prooftree}
\end{equation*}
where the proofs \(\Gamma\to\Delta\) and \(\Phi\to\Psi\) contain no
mixes and \(\Phi\) contains at least one \(A\). Consider the following
proof \(P'\):
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta}
\hypo{\Phi\to\Psi}
\infer2[(\(A\))]{\Gamma,\Phi^*\to\Delta^*,\Psi}
\end{prooftree}
\end{equation*}
In \(P'\), the grade of the mix is equal to \(g(P)\),
\(\rank_l(P')=\rank_l(P)\) and \(\rank_r(P')=\rank_r(P)-1\). Thus by
induction hypothesis, \(\Gamma,\Phi^*\to\Delta^*,\Psi\) is provable without
a mix. Then we construct the proof
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma,\Phi^*\to\Delta^*,\Psi}
\infer1{\text{some exchanges}}
\infer1{\Phi^*,\Gamma\to\Delta^*,\Psi}
\infer1[\(J_2\)]{\Pi^*,\Gamma\to\Delta^*,\Lambda}
\end{prooftree}
\end{equation*}

\item \(\Gamma\) contains no \(A\)'s and \(S_2\) is the lower sequent of a logical
inference whose principal formula is \(A\).
\end{enumerate}
\end{enumerate}
\end{enumerate}
\end{proof}

\begin{theorem}[]
The cut-elimination theorem holds for \(\LJ\)
\end{theorem}

\subsection{Some consequences of the cut-elimination theorem}
\label{sec:org056ccf9}
\begin{definition}[]
By a \textbf{subformula} of a formula \(A\) we mean a formula used in building up
\(A\).

Two formulas \(A\) and \(B\) are said to be \textbf{equivalent}
in \(\LK\)if \(A\equiv B\) is provable in \(\LK\)

In a formula \(A\) an occurrence of a logical symbol, say \(\sharp\) is \textbf{in the
scope} of an occurrences of a logical symbol, say \(\natural\), if in the
construction of \(A\) (from atomic formulas) the stage where \(\sharp\) is
the outermost logical symbol precedes the stage where \(\natural\) is the
outermost logical symbol. Further, a symbol \(\sharp\) is said to be in the
left scope of a \(\supset\) if \(\supset\) occurs in the form \(B\supset C\)
and \(\sharp\) occurs in \(B\)

A formula is called \textbf{prenex} (in prenex form) if no quantifier in it is in the
scope of a propositional connective.
\end{definition}

A proof without a cut contains only subformulas of the formulas occurring in
the end-sequent. A formula is provable iff it is provable by use of its
subformulas only

\begin{theorem}[consistency]
\(\LK\) and \(\LJ\) are consistent
\end{theorem}

\begin{proof}
Suppose \(\to\) were provable in \(\LK\). Then by the cut-elimination
theorem, it would be provable in \(\LK\) without a cut. But this is
impossible, by the subformula property of cut-free proofs
\end{proof}

\begin{theorem}[]
In a cut-free proof in \(\LK\) (or \(\LJ\)) all the formulas which occur in
it are subformulas of the formulas in the end-sequent
\end{theorem}

\begin{theorem}[Gentzen's midsequent theorem for $\LK$]
Let \(S\) be a sequent which consists of prenex formulas only and is provable
in \(\LK\). Then there is a cut-free proof of \(S\) which contains a sequent
(called a \textbf{midsequent}), say \(S'\), which satisfies the following
\begin{enumerate}
\item \(S'\) is quantifier-free
\item Every inference above \(S'\) is either structural or propositional
\item Every inference below \(S'\) is either structural or a quantifier
inference
\end{enumerate}


Thus a midsequent splits the proof into an upper part, which contains the
propositional inferences, and a lower part, which contains the quantifier
inferences.

The above holds reading "\(\LJ\) without \(\vee\)left" in place of \(\LK\)
\end{theorem}
\begin{proof}[outline]
Combining Proposition \ref{prop2.14} and the cut-elimination theorem we may assume that there is a
cut-free proof of \(S\), say \(P\), in which all the initial sequents consist of atmoic formulas
only (\textsubscript{why} do we need atomic formula\_). Let \(I\) be a quantifier inference in \(P\). The number of propositional inference
under \(I\) is called the order of \(I\). The sum of orders for all the quantifier inferences
in \(P\)is called the order of \(P\). The proof is carried out by induction on the order
of \(P\).

Case 1: The order of a proof \(P\) is 0. If there is a propositional inference, take the
lowermost such, and call its lower sequent \(S_0\). Above this sequent there is no quantifier
inference. Therefore if there is a quantifier in or above \(S_0\), then it is introduced by
weakening. Since the proof is cut-free, the weakening formula is a subformula of one of the
formulas in the end-sequent. Hence no propositional inferences apply to it. \label{Problem1} (\textsubscript{don}'t understand\_)
We can thus eliminate
these weakenings and obtain a sequent \(S_0'\) corresponding to \(S_0\). By adding some
weakenings under \(S_0'\) we derive \(S\) and \(S_0'\) serves as the mid-sequent

If there is no propositional inference in \(P\), then take the uppermost quantifier inferences.
Its upper sequent serves as a midsequent

Case 2: The order of \(P\) is not 0. Then there is at least one propositional inference which is
below a quantifier property. Moreover, there is a quantifier inference \(I\) with the following
property: the uppermost logical inference under \(I\) is a propositional inference. Call
it \(I'\). We can lower the order by interchanging the positions of \(I\) and \(I'\). Say \(I\)
is \(\forall\)right, then proof \(P\) is 
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{}
\ellipsis{}{\Gamma\to\Theta,F(a)}
\infer1[\(I\)]{\Gamma\to\Theta,\forall xF(x)}
\ellipsis{(*)}{}
\infer1[\(I'\)]{\Delta\to\Lambda}
\end{prooftree}
\end{equation*}
where the (*)-part of \(P\) contains only structural inferences and \(\Lambda\) contains \(\forall xF(x)\) as a
sequent-formula. Transform \(P\) into the following proof \(P'\):
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Theta,F(a)}
\ellipsis{structural inferences}{\Gamma\to F(a),\Theta,\forall xF(x)}
\ellipsis{}{}
\infer1[\(I'\)]{\Delta\to F(a),\Lambda}
\infer[double]1[\(I\)]{\Delta,\Lambda,\forall xF(x)}
\infer[double]1{\Delta\to\Lambda}
\ellipsis{}{}
\end{prooftree}
\end{equation*}
It is obvious that the order of \(P'\) is less than that of \(P\)
\end{proof}

For technical reasons we introduce the predicate symbol \(\top\) with 0 argument places, and
admit \(\to\top\) as an additional initial sequent. The system which is obtained from \(\LK\)
thus extended is denoted by \(\LKsh\)

\begin{lemma}[]
\label{lemma6.5}
Let \(\Gamma\to\Delta\) be \(\LK\)-provable, and let \((\Gamma_1,\Gamma_2)\)
and \(\Delta_1,\Delta_2\) be arbitrary partitions of \(\Gamma\) and \(\Delta\), respectively (including the cases
that one or more of \(\Gamma_1,\Gamma_2,\Delta_1,\Delta_2\) are empty). We denote such a
partition by \([\{\Gamma_1;\Delta_1\},\{\Gamma_2;\Delta_2\}]\) and call it a partition of the
sequent \(\Gamma\to\Delta\). Then there exists a formula \(C\) of \(\LKsh\) (called an
\textbf{interpolant} of \([\{\Gamma_1;\Delta_1\},\{\Gamma_2;\Delta_2\}]\)) s.t.
\begin{enumerate}
\item \(\Gamma_1\to\Delta_1,C\) and \(C,\Gamma_2\to\Delta_2\) are both \(\LKsh\)-provable
\item All free variables and individual and predicate constants in \(C\) (apart from \(\top\)) occur
both in \(\Gamma_1\cup\Delta_1\) and \(\Gamma_2\cup\Delta_2\)
\end{enumerate}
\end{lemma}

\begin{theorem}[Craig's interpolation theorem for \(\LK\)]
\label{thm6.6}
\begin{enumerate}
\item Let \(A\) and \(B\) be two formulas s.t. \(A\supset B\) is \(\LK\)-provable. If \(A\)
and \(B\) have at least one predicate constant in common, then there exists a formula \(C\),
called an interpolant of \(A\supset B\) s.t. \(C\) contains only those individual constants,
predicate constants and free variables that occur in both \(A\) and \(B\) and s.t.
\(A\supset C\) and \(C\supset B\) are \(\LK\)-provable. If \(A\) and \(B\) contain no
predicate constant in common, then either \(A\to\) or \(\to B\) is \(\LK\)-provable
\item As above, with \(\LJ\) inplace of \(\LK\)
\end{enumerate}
\end{theorem}

\begin{proof}
Assume that \(A\supset B\), and hence \(A\to B\) is provable, and \(A\) and \(B\) have at least
one predicate constant in common. Then by Lemma \ref{lemma6.5}, taking \(A\) as \(\Gamma_1\)
and \(B\) as \(\Delta_2\) (with \(\Gamma_2\) and \(\Delta_1\) empty), there exists a
formula \(C\)satisfying 1 and 2. So \(A\to C\) and \(C\to B\) are \(\LKsh\)-provable. Let \(R\)
be predicate constant which is common to \(A\) and \(B\) and has \(k\) argument places.
Let \(R'\) be \(\forall y_1\dots\forall y_kR(y_1,\dots,y_k)\), where \(y_1,\dots,y_k\) are new bound
variables.  By replacing \(\top\) by \(R'\supset R'\) we can transform \(C\) into a
formula \(C'\) of the original language, s.t. \(A\to C'\) and \(C'\to B\)
are \(\LK\)-provable. \(C'\) is then the desired interpolant.

If there is no predicate common to \(\Gamma_1\cup\Delta_1\) and \(\Gamma_2\cup\Delta_2\) in the
partition, then by Lemma \ref{lemma6.5} there is a \(C\) s.t. \(\Gamma_1\to\Delta_1,C\)
and \(C,\Gamma_2\to\Delta_2\) are provable, and \(C\) consists of \(\top\) and logical symbols
only. Then it can easily be shown, by induction on the complexity of \(C\), that either \(\to C\)
or \(C\to\) is provable. Hence either \(\Gamma_1\to\Delta_1\) or \(\Gamma_2\to\Delta_2\) is provable.
\end{proof}

\begin{proof}[Lemma \cite{lemma6.5}]
The lemma is proved by induction on the number of inferences \(k\), in a cut-free proof
of \(\Gamma\to\Delta\). At each stage there are several cases to consider; we deal with some
examples only.
\begin{enumerate}
\item \(k=0,\Gamma\to\Delta\)  has the form \(D\to D\). There are four
cases: 1.
\([\{D;D\},\{;\}]\), 2. \([\{;\},\{D;D\}]\), 3. \([\{D;\},\{;D\}]\), 4. \(\{;D\},\{D;\}\).
Take for \(C:\neg\top\) in 1, \(\top\) in 2, \(D\) in 3 and \(\neg D\) in 4
\item \(k>0\) and the last inference is \(\wedge\)right:
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta,A}
\hypo{\Gamma\to\Delta,B}
\infer2{\Gamma\to\Delta,A\wedge B}
\end{prooftree}
\end{equation*}
Suppose the partition is \([\{\Gamma_1;\Delta_1,A\wedge B\},\{\Gamma_2;\Delta_2\}]\). Consider
the induced partition of the upper sequents,
viz \([\{\Gamma_1;\Delta_1,A\},\{\Gamma_2;\Delta_2\}]\)
and \([\{\Gamma_1;\Delta_1,B\},\{\Gamma_2;\Delta_2\}]\) respectively. By the induction
hypothesis applied to the subproofs of the upper sequents, there exists interpolants \(C_1\)
and \(C_2\) so that
\(\Gamma_1\to\Delta_1,A,C_1\);\(C_1,\Gamma_2\to\Delta_2\);\(\Gamma_1\to\Delta_1,B,C_2\)
and \(C_2,\Gamma_2\to\Delta_2\) are all \(\LKsh\)-provable. From these
sequents, \(\Gamma_1\to\Delta_1,A\wedge B,C_1\vee C_2\) and \(C_1\vee C_2,\Gamma_2\to\Delta_2\)
\item \(k>0\) and the last inference is \(\forall\)left
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{F(s),\Gamma\to\Delta}
\infer1{\forall xF(x),\Gamma\to\Delta}
\end{prooftree}
\end{equation*}
Suppose \(b_1,\dots,b_n\) are all the free variables and constants which occur in \(s\).
Suppose the partition is \([\{\forall xF(x),\Gamma_1;\Delta_1\},\{\Gamma_2;\Delta_2\}]\). Consider
the induced partition of the upper sequent and apply the induction hypothesis. So there exists
and interpolant \(C(b_1,\dots,b_n)\) so that
\begin{align*}
&F(s),\Gamma_1\to\Delta_1,C(b_1,\dots,b_n)\\
&C(b_1,\dots,b_n),\Gamma_2\to\Delta_2
\end{align*}
are \(\LKsh\)-provable. Let \(b_{i_1},\dots,b_{i_m}\) be all the variables and constants
among \(b_1,\dots,b_n\) which do not occur in \(\{F(x),\Gamma_1;\Delta_1\}\) . Then
\begin{equation*}
\forall y_1\dots\forall y_mC(b_1,\dots,y_1,\dots,y_m,\dots,b_n)
\end{equation*}
where \(b_{i_1},\dots,b_{i_m}\) are replaced by the bound variables, serve as the required
interpolant.

\item \(k>0\) and the last inference is \(\forall\)right
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to\Delta,F(a)}
\infer1{\Gamma\to\Delta,\forall xF(x)}
\end{prooftree}
\end{equation*}
where \(a\) doesn't occur in the lower sequent.

Suppose the partition is \([\{\Gamma_1;\Delta_1,\forall xF(x)\},\{\Gamma_2;\Delta_2\}]\). By the
induction hypothesis there exists an interpolant \(C\) so that \(\Gamma_1\to\Delta_1,F(a),C\)
and \(C,\Gamma_2\to\Delta_2\) are provable. Since \(C\) doesn't contain \(a\), we can derive
\begin{equation*}
\Gamma_1\to\Delta_1,\forall xF(x),C
\end{equation*}
and hence \(C\) serves as the interpolant
\end{enumerate}
\end{proof}

\begin{exercise}
\label{ex6.7}
Let \(A\) and  \(B\) be prenex formulas which have only \(\forall\) and \(\wedge\) as logical
symbols. Assume futhermore that there is at least one predicate constant common to \(A\)
and \(B\). Suppose \(A\supset B\) is provable.

Show that there exists a formula \(C\) s.t.
\begin{enumerate}
\item \(A\supset C\) and \(C\supset B\) are provable
\item \(C\) is a prenex formula
\item the only logical symbols in \(C\) are \(\forall\) and \(\wedge\)
\item the predicate constants in \(C\) are common to \(A\) and \(B\)
\end{enumerate}
\end{exercise}

\begin{definition}[]
\begin{enumerate}
\item A \textbf{semi-term} is an expression like a term, except that bound variables are allowed in its
construction. Let \(t\) be a term and \(s\) a semi-term. We call \(s\) a \textbf{sub-semi-term}
of \(t\) if
\begin{enumerate}
\item \(s\) contain a bound variable (\(s\) is not a term)
\item \(s\) is not a bound variable itself
\item some subterm of \(t\) is obtained from \(s\) by replacing all the bound variables in \(s\)
by appropriate terms
\end{enumerate}
\item A \textbf{semi-formula} is an expression like a formula, except that bound variables are (also) allowed
to occur free in it
\end{enumerate}
\end{definition}

\begin{theorem}[]
Let \(t\) be a term and \(S\) a provable sequent satisfying
\begin{equation}
\label{eq:1}
\text{There is no sub-semi-term of }t\text{ in }S
\end{equation}
Then the sequent which is obtained from \(S\) by replacing all the occurrences of \(t\) in \(S\)
by a free variable is also provable
\end{theorem}

\begin{proof}
Consider a cut-free regular proof of \(S\), say \(P\).  If \ref{eq:1} holds for the lower sequent
of an inference in \(P\) then it holds for the upper sequents. The theorem follows by
mathematical induction on the number of inferences in \(P\)
\end{proof}

\begin{definition}[]
Let \(R_1,\dots,R_m,R\) be predicate constants. Let \(A(R,R_1,\dots,R_m)\) be a sentence in which
all occurrences of \(R,R_1,\dots,R_m\) are indicated. Let \(R'\) be a predicate constant with the
same number of argument-places as \(R\). Let \(B\)
be \(\forall x_1\dots\forall x_k(R(x_1,\dots,x_k)\equiv R'(x_1,\dots,x_k))\), where the string of
quantifiers is empty if \(k=0\). Let \(C\) be \(A(R,R_1,\dots,R_m)\wedge A(R',R_1,\dots,R_m)\). We say
that \(A(R,R_1,\dots,R_m)\) \textbf{defines (in \(\LK\)) \(R\) implicitly} in terms of \(R_1,\dots,R_m\)
if \(C\supset B\) is (\(\LK\)-)provable and we say that \(A(R,R_1,\dots,R_m)\) \textbf{defines
(in \(\LK\)) \(R\) explicitly} in terms of \(R_1,\dots,R_m\) and the individual constants
in \(A(R,R_1,\dots,R_m)\) if there exists a formula \(F(a_1,\dots,a_k)\) containing only the
predicate constants \(R_1,\dots,R_m\) and the individual constants in \(A(R,R_1,\dots,R_m)\) s.t.
\begin{equation*}
A(R,R_1,\dots,R_m)\to\forall x_1\dots\forall x_k
(R(x_1,\dots,x_k)\equiv F(x_1,\dots,x_k))
\end{equation*}
is \(\LK\)-provable
\end{definition}

\begin{proposition}[Beth's definability theorem for $\LK$]
If a predicate constant \(R\) is defined implicitly in terms of \(R_1,\dots,R_m\)
by \(A(R,R_1,\dots,R_m)\), then \(R\) can be defined explicitly in terms of \(R_1,\dots,R_m\) and
the individual constants in \(A(R,R_1,\dots,R_m)\)
\end{proposition}

\begin{proof}[outline]
Let \(c_1,\dots,c_n\) be free variables not occurring in \(A\). Then
\begin{equation*}
A(R,R_1,\dots,R_m),A(R',R_1,\dots,R_m)\to
R(c_1,\dots,c_n)\equiv R'(c_1,\dots,c_n)
\end{equation*}
and hence also
\begin{equation*}
A(R,R_1,\dots,R_m)\wedge R(c_1,\dots,c_k)\to A(R',R_1,\dots,R_m)\supset R'(c_1,\dots,c_n)
\end{equation*}
are provable. Now apply Craig's theorem to the latter sequent. We get
\begin{align*}
&A(R,R_1,\dots,R_m)\wedge R(c_1,\dots,c_k)\supset F(c_1,\dots,c_k)\\
&F(c_1,\dots,sc_k)\supset A(R',R_1,\dots,R_m)\supset R'(c_1,\dots)
\end{align*}
First line implies \(A(R,R_1,\dots,R_m)\to R(c_1,\dots,c_k)\supset F(c_1,\dots,c_k)\). The second line
with the assumption \(A(R,R_1,\dots,R_m)\) shows that
\(A(R,R_1,\dots,R_m)\to F(c_1,\dots,c_k)\supset R(c_1,\dots,c_k)\)
\end{proof}

\begin{proposition}[Robinson]
Assume that the language contains no function constants. Let \(\cala_1\) and \(\cala_2\) be two
consistent axiom systems. Suppose furthermore that, for any sentence \(A\) which is dependent
on \(\cala_1\) and \(\cala_2\), it is not the case that \(\cala_1\to A\) and \(\cala_2\to\neg A\)
are provable. Then \(\cala_1\cup\cala_2\) is consistent
\end{proposition}

\begin{proof}
Suppose \(\cala_1\cup\cala_2\) is not consistent. Then there are axiom sentences \(\Gamma_1\)
and \(\Gamma_2\) from \(\cala_1\) and \(\cala_2\) respectively s.t. \(\Gamma_1,\Gamma_2\to\) is
provable. Since \(\cala_1\) and \(\cala_2\) are each consistent, neither \(\Gamma_1\)
nor \(\Gamma_2\) is empty. Apply Lemma \ref{lemma6.5} to the partition \([\{\Gamma_1;\},\{\Gamma_2;\}]\)
\end{proof}

Let \(\LKp\) and \(\LJp\) denote the quantifier-free parts of \(\LK\) and \(\LJ\)

\begin{theorem}[]
There exist decision procedures for \(\LKp\) and \(\LJp\)
\end{theorem}

\begin{proof}
The following decision procedure was given by gentzen. A sequent of \(\LKp\)  (or \(\LJp\)) is
said to be \textbf{reduced} if in the antecedent the same formula does not occur at more than three places
as sequent formulas, and likewise in the succedent. A sequent \(S'\) is called a \textbf{reduct} of a
sequent \(S\) is \(S'\) is reduced and is obtained from \(S\) by deleting some occurrences of
formulas. Now given a sequent \(S\) of \(\LKp\) (or \(\LJp\)), let \(S'\) be any reduct of \(S\).
We note the following
\begin{enumerate}
\item \(S\) is provable or unprovable according as \(S'\) is provable or unprovable
\item The number of all reduced sequents which contain only subformulas of the formula in \(S\) is
finite
\end{enumerate}


Consider the finite system of sequents as in 2, say \(\cali\).  Collect all initial sequents in
the systems. Call this set \(\cali_0\). Then examine \(\cali-\cali_0\) to see if there is a
sequent which can be the lower sequent of an inference whose upper sequent(s) is (are) one (two)
sequent(s) from \(\cali_0\). Call the set of all sequents which satisfy this
condition \(\cali_1\). Now see if there is a sequent in \((\cali-\cali_0)-\cali_1\) which be the
lower sequent of an inference whose upper sequent(s) is (are) one (two) of the sequent(s)
in \(\cali_0\cup\cali_1\). Continue this process until either the sequent \(S'\) itself is
determined as provable, or the process does not give any new sequent as provable. One of the two
must happen. (Note that the whole argument is finitary)
\end{proof}

\begin{theorem}[Harrop]
\label{Problem2}
\begin{enumerate}
\item Let \(\Gamma\) be a finite sequence of formulas s.t. in each formula of \(\Gamma\) every occurrence
\end{enumerate}
of \(\vee\) and \(\exists\) is either in the scope of a \(\neg\) or in the left scope of
a \(\sup\). This condition will be referred to as (*) in this theorem.
\begin{enumerate}
\item Then \(\Gamma\to A\vee B\) is \(\LJ\)-provable iff  \(\Gamma\to A\) and \(\Gamma\to B\) is \(\LJ\)-provable
\item \(\Gamma\to\exists xF(x)\) is \(\LJ\)-provable iff for some term \(s\), \(\Gamma\to F(s)\) is \(\LJ\)-provable
\end{enumerate}
\begin{enumerate}
\item The following sequents (which are \(\LK\)-provable) are not \(\LJ\)-provable
\begin{gather*}
\neg(\neg A\wedge\neg B)\to A\vee B;\hspace{1cm}
\neg\forall x\neg F(x)\to\exists xF(x)\\
A\supset B\to A\vee B;\hspace{1cm}
\neg\forall xF(x)\to\exists x\neg F(x);\\
\neg A(\wedge B)\to A\vee \neg B
\end{gather*}
\end{enumerate}
\end{theorem}

\begin{proof}
\begin{enumerate}
\item \begin{enumerate}
\item \(\Rightarrow\). Consider a cut-free proof of \(\Gamma\to A\vee B\). The proof is carried
out by induction on the number of inferences below all the inferences for \(\vee\)
and \(\exists\) in the given proof. If the last inference is \(\vee\)right, there is
nothing to prove. Notice that the last inference cannot be \(\vee,\neg\) or \(\exists\)left

Case 1: The last inference is \(\wedge\)left
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{C,\Gamma\to A\vee B}
\infer1{C\wedge D,\Gamma\to A\vee B}
\end{prooftree}
\end{equation*}
Its obvious that \(C\) satisfies the condition (*). Thus the induction hypothesis applies
to the upper sequent; hence either \(C,\Gamma\to A\) or \(C,\Gamma\to B\) is provable. In
either case, the end-sequent can be derived in \(\LJ\)
Case 2: The last inference is \(\supset\)left
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Gamma\to C}
\hypo{D,\Gamma\to A\vee B}
\infer2{C\supset D,\Gamma\to A\vee B}
\end{prooftree}
\end{equation*}
\(D\) satisfies the condition; thus by the induction hypothesis applied to the right upper
sequent, \(D,\Gamma\to A\) or \(D,\Gamma\to B\) is provable.
\item If \(\Gamma\to F(s)\) is \(\LJ\)-provable for some term \(s\).
\end{enumerate}
\end{enumerate}
\end{proof}

\subsection{The predicate calculus with equality\hfill{}\textsc{problem}}
\label{sec:org5e00532}
\begin{definition}[]
The predicate calculus with equality (denoted \(\LKe\)) can be obtained from \(\LK\) by
specifying constant of two argument (=: read equals) and adding the following sequents as
additional initial sequents (\(a=b\) denoting \(=(a,b)\))
\begin{gather*}
\to s=s\\
s_1=t_1,\dots,s_n=t_n\to f(s_1,\dots,s_n)=f(t_1,\dots,t_n)
\end{gather*}
for every function constant \(f\) of \(n\) argument-places (\(n=1,2,\dots\)):
\begin{equation*}
s_1=t_1,\dots,s_n=t_n,R(s_1,\dots,s_n)\to R(t_1,\dots,t_n)
\end{equation*}
for every predicate constant \(R\) of \(n\) argument; where \(s,s_1,\dots,s_n,t_1,\dots,t_n\) are
arbitrary terms

Each such sequent may be called an equality axiom of \(\LKe\)
\end{definition}

\begin{proposition}[]
Let \(A(a_1,\dots,a_n)\) be an arbitrary formula. Then
\begin{equation*}
s_1=t_1,\dots,s_n=t_n,A(s_1,\dots,s_n)\to A(t_1,\dots,t_n)
\end{equation*}
is provable in \(\LKe\) for any terms \(s_i,t_i\). Furthermore, \(s=t\to t=s\)
and \(s_1=s_2,s_2=s_3\to s_1=s_3\) are also provable
\end{proposition}

\begin{definition}[]
Let \(\Gamma_e\) be the set (axiom system) consisting of the following sentences
\begin{gather*}
\forall x(x=x)\\ 
\forall x_1\dots\forall x_n\forall y_1\dots\forall y_n[x_1=y_1\wedge\dots\wedge
x_n=y_n\supset f(x_1,\dots,x_n=f(y_1,\dots,y_n))]
\end{gather*}
for every function constant \(f\) with \(n\) arguments,
\begin{equation*}
\forall x_1\dots\forall x_n\forall y_1\dots\forall y_n[x_1=y_1\wedge\dots\wedge
x_n=y_n\supset R(x_1,\dots,x_n=R(y_1,\dots,y_n))]
\end{equation*}
for every predicate constant \(R\) of \(n\) arguments. Each such sentence is called an \textbf{equality axiom}
\end{definition}

\begin{proposition}[]
A sequent \(\Gamma\to\Delta\) is provable in \(\LKe\) iff \(\Gamma,\Gamma_e\to\Delta\) is provable in \(\LK\)
\end{proposition}

\begin{proof}
All the initial sequents of \(\LKe\) are provable from \(\Gamma_e\)
\end{proof}

\begin{definition}[]
If the cut formula of a cut in \(\LKe\) is of the form \(s=t\), then the cut is called
\textbf{inessential}. It's called \textbf{essential} otherwise
\end{definition}

\begin{theorem}[the cut-elimination theorem for $\LKe$]
If a sequent of \(\LKe\) is \(\LKe\)-provable, then it is \(\LKe\)-provable without an essential cut
\end{theorem}

\begin{proof}
The theorem is proved by removing essential cuts (mixes as a matter of a fact), following the
method used for Theorem \ref{thm5.1}

If the rank is 2, \(S_2\) is an equality axiom and the mix formula is not of the form \(s=t\),
then the mix formula is of the form \(P(t_1,\dots,t_n)\). If \(S_1\) is also an equality axiom,
then it has the form
\begin{equation*}
s_1=t_1,\dots,s_n=t_n,P(s_1,\dots,s_n)\to P(t_1,\dots,t_n)
\end{equation*}
From this and \(S_2\), i.e.,
\begin{equation*}
t_1=r_1,\dots,t_n=r_n,P(t_1,\dots,t_n)\to P(r_1,\dots,r_n)
\end{equation*}
we obtain by a mix
\begin{equation*}
s_1=t_1,\dots,s_n=t_n,t_1=r_1,\dots,t_n=r_n,P(s_1,\dots,s_n)\to P(r_1,\dots,r_n)
\end{equation*}
This may be replaced by
\begin{align*}
&s_i=t_i,t_i=r_i\to s_i=r_i\quad(i=1,2,\dots,n)\\
&s_1=r_1,\dots,s_n=r_n,P(s_1,\dots,s_n)\to P(r_1,\dots,r_n)
\end{align*}
and then repeated cuts of \(s_i=r_i\) to produce the same end-sequent. All cuts introduced here
are inessential

If \(P(t_1,\dots,t_n)\) in \(S_2\) is a weakening formula, then the mix inference is
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{s_1=t_1,\dots,s_n=t_n,P(s_1,\dots,s_n)\to P(t_1,\dots,t_n)}
\hypo{P(t_1,\dots,t_n),\Pi\to\Lambda}
\infer2{s_1=t_1,\dots,s_n=t_n,P(s_1,\dots,s_n),\Pi\to\Lambda}
\end{prooftree}
\end{equation*}
Transform this into
\begin{equation*}
\begin{prooftree}%[center=false]
\hypo{\Pi\to\Lambda}
\infer[double]1{\text{end-sequent}}
\end{prooftree}
\end{equation*}
\end{proof}

\begin{exercise}
\label{ex7.7}
A sequent of the form
\begin{equation*}
s_1=t_1,\dots,s_n=t_n\to s=t
\end{equation*}
is said to be simple if it is obtained from sequents of the following four forms by applications
of exchanges, contractions, cuts, and weakening left.
\begin{enumerate}
\item \(\to s=s\)
\item \(s=t\to t=s\)
\item \(s_1=s_2,s_2=s_3\to s_1=s_3\)
\item \(s_1=t_1,\dots,s_m=t_m\to f(s_1,\dots,s_m)=f(t_1,\dots,t_m)\)
\end{enumerate}


Prove that if \(s_1=s_1,\dots,s_m=s_m\to s=t\) is simple, then \(s=t\) is of the form \(s=s\). As
a special case, if \(\to s=t\) is simple, then \(s=t\) is of the form \(s=s\)

Let \(\LKe'\) be the system which is obtained from \(\LK\) adding the following sequents as
initial sequents
\begin{enumerate}
\item simple sequents
\item sequents of the form
\begin{equation*}
s_1=t_1,\dots,s_m=t_m,R(s_1',\dots,s_n')\to R(t_1',\dots,t_n')
\end{equation*}
where \(s_1=t_1,\dots,s_m=t_m\to s_i'=t_i'\) is simple for each \(i\)
\end{enumerate}


First prove that the initial sequents of \(\LKe'\) are closed under cuts and that if
\begin{equation*}
R(s_1,\dots,s_n)\to R(t_1,\dots,t_n)
\end{equation*}
is an initial sequent of \(\LKe'\) (where \(R\) is not =), then it is of the form \(D\to D\).
Finally prove that the cut-elimination theorem (without the exception of inessential cuts)
holds for \(\LKe'\)
\end{exercise}

\begin{proof}
\begin{enumerate}
\item Consider the complexity of \(s\)?

If \(s\) is a variable, we can only get this by \(v_i=v_i\)
\end{enumerate}
\end{proof}

\subsection{The completeness theorem}
\label{sec:org50c1fc2}
\begin{definition}[]
\begin{enumerate}
\item Let \(L\) be a language. By a \textbf{structure} for \(L\) we mean a pair \(\la D,\phi\ra\), where \(D\)
is a non-empty set and \(\phi\) is a map from the constants of \(L\) s.t.
\begin{enumerate}
\item if \(k\) is an individual constant, then \(\phi k\) is an element of \(D\)
\item if \(f\) is a function constant of \(n\) arguments, then \(\phi f\) is a mapping from \(D^n\) to \(D\)
\item if \(R\) is a predicate constant of \(n\) arguments, then \(\phi R\) is a subset of \(D^n\)
\end{enumerate}
\item An \textbf{interpretation} of \(L\) is a structure \(\la D,\phi\ra\) together with a mapping \(\phi_0\)
from variables into \(D\). We may denote an interpretation \((\la D,\phi\ra,\phi_0)\) simply
by \(\fF\). \(\phi_0\) is called an assignment from \(D\)
\item We say that an interpretation \(\fF=(\la C,\phi\ra,\phi_0)\) \textbf{satisfies} a formula \(A\) if this
follows from the following inductive definition
\begin{enumerate}
\item For every semi-term \(t\), \(\phi(a)=\phi_0(a)\) and  for a\(\phi(x)=\phi_0(x)\)ll free
variables \(a\) and bound variables \(x\). next if \(f\) is a function constant and \(t\)
is a semi-term for which \(\phi t\) is already defined, then \(\phi(f(t))\) is defined to
be \((\phi f)(\phi t)\)
\end{enumerate}
\end{enumerate}
\end{definition}

\begin{theorem}[Completeness and soundness]
A formula is provable in \(\LK\) iff it is valid
\end{theorem}

\begin{lemma}[]
Let \(S\) be a sequent. Then either there is a cut-free proof of \(S\), or there is an
interpretation which does not satisfy \(S\) (and hence \(S\) is not valid)
\end{lemma}

\begin{proof}
We will define, for each sequent \(S\), a (possibly infinite) tree, called the reduction tree
for \(S\), from which we can obtain either a cut-free proof of \(S\) or an interpretation not
satisfying \(S\). This reduction tree for \(S\) contains a sequent at each node. It is
constructed in stages as follows

Stage 0: Write \(S\) at the bottom of the tree

Stage \(k\) (\(k>0\)): This is defined by cases
\begin{enumerate}
\item Every topmost sequent has a formula common to its antecedent and succedent. Then stop.
\item This stage is defined according as
\begin{equation*}
k\equiv 0,1,2,\dots,12\mod 13
\end{equation*}
\(k\equiv0\) and \(k\equiv1\) concern the symbol \(\neg\); \(k\equiv2\) and \(k\equiv3\)
concern \(\wedge\); \(k\equiv4\) and \(k\equiv5\) concern \(\vee\); \(k\equiv6\)
and \(k\equiv7\) concern \(\supset\); \(k\equiv8\) and \(k\equiv9\)
concern \(\forall\); \(k\equiv10\) and \(k\equiv11\) concern equiv \(\exists\)
\end{enumerate}


Assume that there are no individual or function constants

All the free variables which occur in any sequent which has been obtained at or before
stage \(k\) are said to be "available at stage \(k\)". In case there is none, pick any free
variable and say that it is available
\begin{enumerate}
\item \(k\equiv 0\). Let \(\Pi\to\Lambda\) be any topmost sequent of the tree which has been defined
by stage \(k-1\). Let \(\neg A_1,\dots,\neg A_n\) be all the formulas in \(\Pi\) whose outermost logical
symbol is \(\neg\), and to which no reduction has been applied in previous stages. Then write
down
\begin{equation*}
\Pi\to\Lambda,A_1,\dots,A_n
\end{equation*}
above \(\Pi\to\Lambda\). We say that a \(\neg\)left reduction has been applied
to \(\neg A_1,\dots,\neg A_n\)
\item \(k\equiv1\). Let \(\neg A_1,\dots,\neg A_n\) be all the formulas in \(\Lambda\) whose outermost logical
symbol is \(\neg\) and to which no reduction has been applied so far. Then write down
\begin{equation*}
A_1,\dots,A_n,\Pi\to\Lambda
\end{equation*}
above \(\Pi\to\Lambda\). We say that a \(\neg\)right reduction has been applied
to \(\neg A_1,\dots,\neg A_n\).
\item \(k\equiv2\). Let \(A_1\wedge B_1,\dots,A_n\wedge B_n\) be all the formulas in \(\Pi\) whose
outermost logical symbols is \(\wedge\) and to which no reduction has been applied yet. Then
write down
\begin{equation*}
A_1,B_1,A_2,B_2,\dots,A_n,B_n,\Pi\to\Lambda
\end{equation*}
above \(\Pi\to\Lambda\). We say that an \(\wedge\)left reduction has been applied to
\begin{equation*}
A_1\wedge B_1,\dots,A_n\wedge B_n
\end{equation*}
\item \(k\equiv3\). Let \(A_1\wedge B_1,\dots,A_n\wedge B_n\) be all the formulas in \(\Pi\) whose
outermost logical symbols is \(\wedge\) and to which no reduction has been applied yet. Then
write down
\begin{equation*}
\Pi\to\Lambda, C_1,\dots,C_n
\end{equation*}
where \(C_i\) is either \(A_i\) or \(B_i\), above \(\Pi\to\Lambda\). Take all possible
combinations of such; so there are \(2^n\) such sequents above \(\Pi\to\Lambda\). We say that
an \(\wedge\)right reduction has been applied to \(A_1\wedge B_1,\dots,A_n\wedge B_n\)
\end{enumerate}
\end{proof}



\subsection{{\bfseries\sffamily TODO} ALL the problems}
\label{sec:org32ae5fe}
\ref{Problem1}
\ref{Problem2}
\end{document}